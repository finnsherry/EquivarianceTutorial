{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fb68fa1",
   "metadata": {},
   "source": [
    "# Equivariance Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510f9415",
   "metadata": {},
   "source": [
    "In this tutorial, we will discuss the concept of _equivariance_. As a model problem, we consider classifying FashionMNIST, though the concepts can be easily extended to other image processing such as segmentation and denoising (and also tasks that don't involve images...). FashionMNIST is a dataset consisting of thumbnails of items of clothing from Zalando, accompanied by a label (`[\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]`). Throughout this tutorial, we will use an \"Ankle boot\" sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e9d14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import affine_grid, grid_sample, relu, softmax, pad, conv2d\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import Normalize\n",
    "from models import CNN, PDEGCNN\n",
    "from lietorch.nn.m2 import LiftM2Cakewavelets\n",
    "from lietorch.nn.r2 import morphological_convolution_r2, morphological_kernel_r2_isotropic\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.rcParams['figure.constrained_layout.use'] = True\n",
    "\n",
    "shoe = read_image(\"content/shoe.png\")[None, ...] / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc0bb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "ax.set_axis_off()\n",
    "ax.set_title(\"Ankle boot\")\n",
    "ax.imshow(shoe.squeeze());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a06c21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "\n",
    "def logits_to_label(logits):\n",
    "    return labels[logits.argmax()]\n",
    "\n",
    "norm = Normalize(0.5, 0.5)\n",
    "\n",
    "cnn_model = CNN()\n",
    "cnn_model.load_state_dict(torch.load(\"CNN.pth\", weights_only=True))\n",
    "cnn_model.eval()\n",
    "\n",
    "def cnn(image):\n",
    "    with torch.no_grad():\n",
    "        logits = cnn_model(norm(image))[0]\n",
    "    return logits_to_label(logits), softmax(logits, dim=-1)\n",
    "\n",
    "pdegcnn_model = PDEGCNN()\n",
    "pdegcnn_model.load_state_dict(torch.load(\"PDEGCNN.pth\", weights_only=True))\n",
    "pdegcnn_model.eval()\n",
    "\n",
    "def pdegcnn(image):\n",
    "    with torch.no_grad():\n",
    "        logits = pdegcnn_model(norm(image))[0]\n",
    "    return logits_to_label(logits), softmax(logits, dim=-1)\n",
    "\n",
    "def plot_classification(image, model, model_name, ax):\n",
    "    probs = model(image)[1]\n",
    "    colours = len(labels) * [\"tab:blue\"]\n",
    "    colours[probs.argmax()] = \"tab:red\"\n",
    "    ax.bar(labels, probs, color=colours)\n",
    "    ax.set_title(model_name)\n",
    "    ax.set_xlabel(\"Class\")\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_xticks(range(len(labels)))\n",
    "    ax.set_xticklabels(labels, rotation=45, ha='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975665e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(image, x, A):\n",
    "    \"\"\"Apply action (x, A) to image with replication padding.\"\"\"\n",
    "    B, C, H, W = image.shape\n",
    "    x = torch.tensor([-1., 1.]) * x\n",
    "    affine_matrix = torch.hstack((torch.linalg.inv(A.T), x[None, ...].T))\n",
    "    grid = affine_grid(affine_matrix[None, ...], (B, C, H, W), align_corners=False)\n",
    "    return grid_sample(image, grid, align_corners=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fc9028",
   "metadata": {},
   "source": [
    "## Lie Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbda144d",
   "metadata": {},
   "source": [
    "> **Definition (Lie Group)** $G$ is a _Lie group_ if it is \n",
    "> 1. a _smooth manifold_ - so smooth and looks locally like $\\mathbb{R}^n$ - and\n",
    "> 2. a _group_ - we have a smooth, well-behaved product $\\cdot: G \\times G \\to G$.\n",
    "\n",
    "The most important Lie groups (imo) encode continuous symmetries on other spaces, with the group product simply given by composition.\n",
    "\n",
    "> **Example (Translation Group)**\n",
    "> The $n$-dimensional _translation group_ $\\mathbb{R}^n$ acts on Euclidean space $\\mathbb{R}^n$ by translation, namely\n",
    "> $$ (\\mathbf{x}, \\mathbf{y}) \\mapsto \\mathbf{x} + \\mathbf{y}, $$\n",
    "> and has group product\n",
    "> $$ (\\mathbf{x}, \\mathbf{y}) \\mapsto \\mathbf{x} + \\mathbf{y}. $$\n",
    "> Consequently, $\\mathbb{R}^n$ also acts on the functions on Euclidean space by\n",
    "> $$ (\\mathbf{x}, f) \\mapsto (\\mathbf{y} \\mapsto f(\\mathbf{y} - \\mathbf{x})). $$\n",
    "Of course, this is an incredibly boring example. \n",
    "Slightly less trivial is the following:\n",
    "> **Example (Special Orthogonal Group)**\n",
    "> The _special orthogonal group_ $\\operatorname{SO}(n)$ acts on Euclidean space $\\mathbb{R}^n$ by rotation, namely\n",
    "> $$ (R, \\mathbf{y}) \\mapsto R\\mathbf{y}, $$\n",
    "> and has group product\n",
    "> $$ (R, S) \\mapsto RS, $$\n",
    "> Consequently, $\\operatorname{SO}(n)$ also acts on the functions on Euclidean space by\n",
    "> $$ (R, f) \\mapsto (\\mathbf{x} \\mapsto f(R^{-1} \\mathbf{x})). $$\n",
    "Here, we represent the elements of $\\operatorname{SO}(n)$ as $n \\times n$ orthogonal matrices with determinant $1$. \n",
    "For example, in two dimensions the counter-clockwise rotation by angle $\\theta$ is given by\n",
    "$$ R = \\begin{pmatrix} \\cos(\\theta) & -\\sin(\\theta) \\\\\n",
    "\\sin(\\theta) & \\cos(\\theta) \\end{pmatrix}. $$\n",
    "\n",
    "In this example the group and the space that is acted on can no longer be identified.\n",
    "\n",
    "We get our favourite group by combining the two previous ones:\n",
    "> **Example (Special Euclidean Group)**\n",
    "> The _special Euclidean group_ $\\operatorname{SE}(n) := \\mathbb{R}^n \\rtimes \\operatorname{SO}(n)$ acts on Euclidean space $\\mathbb{R}^n$ by roto-translation, namely\n",
    "> $$ ((\\mathbf{x}, R), \\mathbf{y}) \\mapsto \\mathbf{x} + R\\mathbf{y}, $$\n",
    "> and has group product\n",
    "> $$ ((\\mathbf{x}, R), (\\mathbf{y}, S)) \\mapsto (\\mathbf{x} + R\\mathbf{y}, RS). $$\n",
    "> Consequently, $\\operatorname{SE}(n)$ also acts on the functions on Euclidean space by\n",
    "> $$ (R, f) \\mapsto (\\mathbf{y} \\mapsto f(R^{-1}(\\mathbf{y} - \\mathbf{x}))). $$\n",
    "\n",
    "> _Remark_ The actions on functions are examples of so-called _group representations_, a term often encountered in the equivariance literature. For the sake of simplicity here we simply refer to them as actions.\n",
    "\n",
    "Finally, we have the most simple group action: doing nothing:\n",
    "> **Definition (Trivial Action)** Let $G$ be a Lie group and $X$ a set. Then we $G$ acts _trivially_ on $X$ if $g x = x$ for all $g \\in G$, $x \\in X$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb35a781",
   "metadata": {},
   "source": [
    "Many problems have inherent symmetries. For example, if we want to classify the object in an image, rotating the object shouldn't change the classification: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db71d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].set_axis_off()\n",
    "ax[1].set_axis_off()\n",
    "ax[0].set_title(\"Ankle boot\")\n",
    "ax[1].set_title(\"Still an ankle boot\")\n",
    "\n",
    "x = torch.tensor([0., 0.])\n",
    "R = torch.tensor([[1., 0.], [0., 1.]])\n",
    "ax[0].imshow(transform(shoe, x, R).squeeze())\n",
    "\n",
    "# Your roto-translation here ⬇️\n",
    "x = torch.tensor([0., 0.])\n",
    "theta = torch.tensor([0.8712346])\n",
    "R = torch.tensor([\n",
    "    [torch.cos(theta), -torch.sin(theta)],\n",
    "    [torch.sin(theta), torch.cos(theta)]\n",
    "])\n",
    "ax[1].imshow(transform(shoe, x, R).squeeze());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988d66dc",
   "metadata": {},
   "source": [
    "Lie groups give us a mathematically formal way of thinking about these symmetries. In particular, we can now define _equivariance_, which in essence is a symmetry preservation property."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2c953e",
   "metadata": {},
   "source": [
    "## Equivariance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de73448c",
   "metadata": {},
   "source": [
    "> **Definition (Equivariance)** Let $G$ be a Lie group acting on $U$ and $V$. \n",
    "> $\\Phi: U \\to V$ is called _equivariant_ if it commutes with the group actions, i.e.\n",
    "> $$ \\Phi \\circ g = g \\circ \\Phi, $$\n",
    "> for all $g \\in G$.\n",
    "\n",
    "If the action on $V$ is trivial, then we say $\\Phi$ is _invariant_. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a405703",
   "metadata": {},
   "source": [
    "Let's work this out for our classification problem.\n",
    "- We can see images as functions on $\\mathbb{R}^2$, on which the Lie group $\\operatorname{SE}(2)$ acts by roto-translation: $(\\mathbf{x}, R) f(\\vec{y}) = f(R^{-1} (\\mathbf{y} - \\mathbf{x}))$.\n",
    "- We have a classifier $\\Phi$ which maps an image $f: \\mathbb{R}^2 \\to \\mathbb{R}$ to a probability distribution $p \\in \\mathbb{P}_c := \\{(p_1, \\ldots, p_c) \\mid \\sum_{i = 1}^c p_i = 1, p_i \\geq 0\\}$ over labels $\\{1, \\ldots, c\\}$, where $c$ is the number of classes.\n",
    "- $\\operatorname{SE}(2)$ acts trivially on the range $\\mathbb{P}_c$, so we have $(\\mathbf{x}, R) p = p$ for all $p \\in \\mathbb{P}_c$.\n",
    "\n",
    "Then the classifier is invariant if $\\Phi(f) \\circ g = g \\circ \\Phi(f) = \\Phi(f)$ for all $g \\in \\operatorname{SE}(2)$ and images $f: \\mathbb{R}^2 \\to \\mathbb{R}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9118f875",
   "metadata": {},
   "source": [
    "In this problem invariance is clearly a desirable property. But how would we go about constructing an invariant classifier? \n",
    "\n",
    "We could train a normal convolutional neural network, and hope that it learns to be invariant. This is highly unlikely, unless we perform _data augmentation_, and even then there are no guarantees.\n",
    "\n",
    "Alternatively, we could construct a neural network architecture that is inherently invariant. For this, we can make use of the following result:\n",
    "> **Lemma (Composition of Equivariant Maps)** Let $G$ be a Lie group acting on $U$, $V$, and $W$. Suppose $\\Phi: U \\to V$ and $\\Psi: V \\to W$ are equivariant. Then, their composition $\\Psi \\circ \\Phi: U \\to W$ is also equivariant. \n",
    "\n",
    "_proof_: Simply note that $\\Psi \\circ \\Phi \\circ g = \\Psi \\circ g \\circ \\Phi = g \\circ \\Psi \\circ \\Phi$.\n",
    "\n",
    "Hence, we can make an equivariant neural network architecture by composing equivariant layers. A typical layer in a neural network consists of the composition of something linear (e.g. matrix multiplication, convolution, linear combinations) with something nonlinear (e.g. activation function, normalisation). Common nonlinearities such as the ReLU activation function act point-wise; it is not hard to see that such point-wise operations are equivariant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b233b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([0., 0.])\n",
    "theta = torch.tensor([torch.pi/2]) # Random number\n",
    "R = torch.tensor([\n",
    "    [torch.cos(theta), -torch.sin(theta)],\n",
    "    [torch.sin(theta), torch.cos(theta)]\n",
    "])\n",
    "\n",
    "rotation_before_relu = relu(transform(shoe - 0.5, x, R))\n",
    "relu_before_rotation = transform(relu(shoe - 0.5), x, R)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "ax[0].set_axis_off()\n",
    "ax[1].set_axis_off()\n",
    "ax[2].set_axis_off()\n",
    "ax[0].set_title(\"Rotation before ReLU\")\n",
    "ax[1].set_title(\"ReLU before rotation\")\n",
    "ax[2].set_title(\"Difference\")\n",
    "ax[0].imshow(rotation_before_relu.squeeze())\n",
    "ax[1].imshow(relu_before_rotation.squeeze())\n",
    "cbar = ax[2].imshow((relu_before_rotation - rotation_before_relu).squeeze())\n",
    "fig.colorbar(cbar, ax=ax[2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cffd30",
   "metadata": {},
   "source": [
    "We're working with images in this tutorial; convolutions are a natural choice for the linear part. In a convolutional layer an image is convolved/cross-correlated with a trainable filter (Fig. 5.3 from [1]):\n",
    "![Schematic depiction of a convolution.](content/convolution.png)\n",
    "Convolutional layers are translation equivariant: if you shift the input image, the output is shifted accordingly (up to boundary effects...):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8274b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = torch.randn(1, 1, 3, 3)\n",
    "\n",
    "k = 1 # number of pixels to shift\n",
    "padding = k+1 # deal with boundary issues\n",
    "x_before = torch.tensor([2 * k / (shoe.shape[-1] + 2 * padding), 0.])\n",
    "x_after = torch.tensor([2 * k / (shoe.shape[-1] + 2 * (padding - 1)), 0.])\n",
    "theta = torch.tensor([0.])\n",
    "R = torch.tensor([\n",
    "    [torch.cos(theta), -torch.sin(theta)],\n",
    "    [torch.sin(theta), torch.cos(theta)]\n",
    "])\n",
    "\n",
    "shift_before_convolution = conv2d(transform(pad(shoe, 4*[padding], mode=\"constant\"), x, R), kernel, torch.tensor([0.]))\n",
    "convolution_before_shift = transform(conv2d(pad(shoe, 4*[padding], mode=\"constant\"), kernel, torch.tensor([0.])), x, R)\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
    "ax[0, 0].set_axis_off()\n",
    "ax[0, 1].set_axis_off()\n",
    "ax[1, 0].set_axis_off()\n",
    "ax[1, 1].set_axis_off()\n",
    "ax[0, 0].set_title(\"Shift before convolution\")\n",
    "ax[0, 1].set_title(\"Convolution before shift\")\n",
    "ax[1, 0].set_title(\"Difference\")\n",
    "ax[1, 1].set_title(\"Convolution kernel\")\n",
    "ax[0, 0].imshow(shift_before_convolution.squeeze())\n",
    "ax[0, 1].imshow(convolution_before_shift.squeeze())\n",
    "cbar = ax[1, 0].imshow((convolution_before_shift - shift_before_convolution).squeeze())\n",
    "fig.colorbar(cbar, ax=ax[1, 0])\n",
    "ax[1, 1].imshow(kernel.squeeze());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dda5ed",
   "metadata": {},
   "source": [
    "However, convolutional layers typically won't be rotation equivariant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002a62e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([0., 0.])\n",
    "theta = torch.tensor([torch.pi/2])\n",
    "R = torch.tensor([\n",
    "    [torch.cos(theta), -torch.sin(theta)],\n",
    "    [torch.sin(theta), torch.cos(theta)]\n",
    "])\n",
    "\n",
    "rotation_before_convolution = conv2d(transform(shoe, x, R), kernel, torch.tensor([0.]))\n",
    "convolution_before_rotation = transform(conv2d(shoe, kernel, torch.tensor([0.])), x, R)\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
    "ax[0, 0].set_axis_off()\n",
    "ax[0, 1].set_axis_off()\n",
    "ax[1, 0].set_axis_off()\n",
    "ax[1, 1].set_axis_off()\n",
    "ax[0, 0].set_title(\"Rotation before convolution\")\n",
    "ax[0, 1].set_title(\"Convolution before rotation\")\n",
    "ax[1, 0].set_title(\"Difference\")\n",
    "ax[1, 1].set_title(\"Convolution kernel\")\n",
    "ax[0, 0].imshow(rotation_before_convolution.squeeze())\n",
    "ax[0, 1].imshow(convolution_before_rotation.squeeze())\n",
    "cbar = ax[1, 0].imshow((convolution_before_rotation - rotation_before_convolution).squeeze())\n",
    "fig.colorbar(cbar, ax=ax[1, 0])\n",
    "ax[1, 1].imshow(kernel.squeeze());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61dc677",
   "metadata": {},
   "source": [
    "Indeed, convolutions are rotation equivariant if and only if the kernel is isotropic. We can achieve this by averaging a normal (anisotropic) kernel over all possible rotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb4fdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "isotropic_kernel = (\n",
    "    kernel + \n",
    "    torch.rot90(kernel, dims=(-2, -1)) + \n",
    "    torch.rot90(kernel, k=-1, dims=(-2, -1)) +\n",
    "    torch.rot90(torch.rot90(kernel, dims=(-2, -1)), dims=(-2, -1))\n",
    ") / 4\n",
    "\n",
    "x = torch.tensor([0., 0.])\n",
    "theta = torch.tensor([torch.pi/2])\n",
    "R = torch.tensor([\n",
    "    [torch.cos(theta), -torch.sin(theta)],\n",
    "    [torch.sin(theta), torch.cos(theta)]\n",
    "])\n",
    "\n",
    "rotation_before_convolution = conv2d(transform(shoe, x, R), isotropic_kernel, torch.tensor([0.]))\n",
    "convolution_before_rotation = transform(conv2d(shoe, isotropic_kernel, torch.tensor([0.])), x, R)\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
    "ax[0, 0].set_axis_off()\n",
    "ax[0, 1].set_axis_off()\n",
    "ax[1, 0].set_axis_off()\n",
    "ax[1, 1].set_axis_off()\n",
    "ax[0, 0].set_title(\"Rotation before convolution\")\n",
    "ax[0, 1].set_title(\"Convolution before rotation\")\n",
    "ax[1, 0].set_title(\"Difference\")\n",
    "ax[1, 1].set_title(\"Convolution kernel\")\n",
    "ax[0, 0].imshow(rotation_before_convolution.squeeze())\n",
    "ax[0, 1].imshow(convolution_before_rotation.squeeze())\n",
    "cbar = ax[1, 0].imshow((convolution_before_rotation - rotation_before_convolution).squeeze())\n",
    "fig.colorbar(cbar, ax=ax[1, 0])\n",
    "ax[1, 1].imshow(isotropic_kernel.squeeze());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd89f72",
   "metadata": {},
   "source": [
    "One limitation of this approach is that we are greatly limiting the number of models that can be expressed with the same number of parameters. For example, if we rotate the initial kernel, then that will lead to the same isotropic kernel, even though the kernel parameters are different. This issue can be addressed by _lifting_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fc8457",
   "metadata": {},
   "source": [
    "## Lifting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8529885",
   "metadata": {},
   "source": [
    "Up to now, we have seen images as functions that map the plane $\\mathbb{R}^2$ to a scalar in $\\mathbb{R}$. Roughly speaking, the gray value (or maybe the change thereof) at a given point is a measure of the presence of structure at that location. However, when we look at an image, we can say more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49c2097",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross = torch.zeros(9, 9, 3)\n",
    "cross[4, 1:8] = 1.\n",
    "cross[1:8, 4] = 1.\n",
    "cross[4, 2] = torch.tensor([1., 0., 0.])\n",
    "cross[2, 4] = torch.tensor([0., 0., 1.])\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "ax.set_axis_off()\n",
    "ax.imshow(cross);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afa9024",
   "metadata": {},
   "source": [
    "In this simple image of a cross, we can see that the red point is horizontally oriented, while the blue dot is vertically oriented. In other words, at the position of the red dot and the horizontal orientation, there is structure present, but not at e.g. the position of the red dot and the vertical orientation. Hence, we can ascribe to every position and orientation a gray value; we call this an _orientation score_:\n",
    "> **Definition (Orientation Score Transform)** Let $\\psi : \\mathbb{R}^2 \\to \\mathbb{R}$ be a wavelet. Then the _orientation score transform_ $\\mathcal{W}_\\psi$ maps an image $f : \\mathbb{R}^2 \\to \\mathbb{R}$ to an _orientation score_ $\\mathcal{W}_\\psi f : \\mathbb{R}^2 \\times S^1 \\cong \\operatorname{SE}(2) \\to \\mathbb{R}$ via \n",
    "> $$ \\mathcal{W}_\\psi f(\\mathbf{x}, \\theta) = \\int_{\\mathbb{R}^2} ((\\mathbf{x}, R_\\theta) \\psi)(\\mathbf{y}) f(\\mathbf{y}) \\mathrm{d} \\mathbf{y} = \\int_{\\mathbb{R}^2} \\psi(R_\\theta^{-1} (\\mathbf{y} - \\mathbf{x})) f(\\mathbf{y}) \\mathrm{d} \\mathbf{y}. $$\n",
    "Classically, we choose the filter wavelet $\\psi$ to pick up horizontally oriented features; then the gray scale values in the \"image\" $\\mathcal{W}_\\psi f(\\cdot, \\theta): \\mathbb{R}^2 \\to \\mathbb{R}$ are a measure for the presence of a feature at some position with orientation $\\theta$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ecb95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Or = 16\n",
    "cross = torch.zeros(1, 1, 64, 64)\n",
    "cross[..., 31:34, 8:56] = 1.\n",
    "cross[..., 8:56, 31:34] = 1.\n",
    "cakewavelet_lift = LiftM2Cakewavelets(cross.shape[-3], Or, inflection_point=1.)\n",
    "lifted_cross = cakewavelet_lift(cross)\n",
    "\n",
    "k = 0\n",
    "dtheta = 2 * torch.pi / Or\n",
    "fig, ax = plt.subplots(1, 4, figsize=(20, 5))\n",
    "ax[0].set_axis_off()\n",
    "ax[1].set_axis_off()\n",
    "ax[2].set_axis_off()\n",
    "ax[3].set_axis_off()\n",
    "ax[0].set_title(\"$f$\")\n",
    "ax[1].set_title(fr\"$\\mathcal{{W}}_\\psi f(\\cdot , {k * dtheta / torch.pi:.2f} \\pi)$\")\n",
    "ax[2].set_title(fr\"$\\mathcal{{W}}_\\psi f(\\cdot , {(k+Or//4) * dtheta / torch.pi:.2f} \\pi)$\")\n",
    "ax[3].set_title(r\"$\\sum_{\\theta \\in S^1} \\mathcal{W}_\\psi f(\\cdot , \\theta)$\")\n",
    "ax[0].imshow(cross.squeeze())\n",
    "ax[1].imshow(lifted_cross[0, 0, k])\n",
    "ax[2].imshow(lifted_cross[0, 0, k+(Or//4)])\n",
    "ax[3].imshow(lifted_cross.sum(-3).squeeze());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a55aebb",
   "metadata": {},
   "source": [
    "The orientation score transform is equivariant for any wavelet $\\psi$:\n",
    "> **Lemma (Orientation Score Transform is Equivariant)**\n",
    "> Let $\\psi, f: \\mathbb{R}^2 \\to \\mathbb{R}$, and let $g \\in \\operatorname{SE}(2)$. Then,\n",
    "> $$ g (\\mathcal{W}_\\psi f) = \\mathcal{W}_\\psi (g f). $$\n",
    "_proof:_ We can simply rewrite:\n",
    "$$\\begin{split}\n",
    "(\\mathbf{x}, R) (\\mathcal{W}_\\psi f)(\\mathbf{y}, S) & := \\mathcal{W}_\\psi f ((\\mathbf{x}, R)^{-1} (\\mathbf{y}, S)) = \\int_{\\mathbb{R}^2} (\\mathbf{x}, R)^{-1} (\\mathbf{y}, S) \\psi(\\mathbf{z}) f(\\mathbf{z}) \\mathrm{d} \\mathbf{z} = \\int_{\\mathbb{R}^2} \\psi((\\mathbf{y}, S)^{-1} (\\mathbf{x}, R) \\mathbf{z}) f(\\mathbf{z}) \\mathrm{d} \\mathbf{z} \\\\\n",
    "& = \\int_{\\mathbb{R}^2} \\psi((\\mathbf{y}, S)^{-1} \\mathbf{v}) f((\\mathbf{x}, R)^{-1} \\mathbf{v}) \\mathrm{d} (\\mathbf{x}, R)^{-1} \\mathbf{v} \\overset{(1)}{=} \\int_{\\mathbb{R}^2} \\psi((\\mathbf{y}, S)^{-1} \\mathbf{v}) f((\\mathbf{x}, R)^{-1} \\mathbf{v}) \\mathrm{d} \\mathbf{v} \\\\\n",
    "& = \\mathcal{W}_\\psi ((\\mathbf{x}, R) f) (\\mathbf{y}, S),\n",
    "\\end{split}$$\n",
    "where we used the $\\operatorname{SE}(2)$ invariance of the standard Lebesgue measure in $(1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1264cdb9",
   "metadata": {},
   "source": [
    "We now have a way of lifting images from $\\mathbb{R}^2$ to orientation scores on the group $\\operatorname{SE}(2)$. The next step is to find equivariant operators on such orientation scores. It turns out that convolutions can be generalised to group convolutions. \n",
    "> **Definition (Group Convolution)** Let $G$ be a Lie group, and let $f, k : G \\to \\mathbb{R}$ be functions thereon. Then we define the _group convolution_ of $f$ and $k$ as\n",
    "> $$ (k * f)(g) := \\int_G k(h^{-1} g) f(h) \\mathrm{d} h. $$\n",
    "\n",
    "To get a feel for group convolutions, consider the following examples.\n",
    "> **Example (Convolution on the Translation Group)**\n",
    "> Let $f, k : \\mathbb{R}^2 \\to \\mathbb{R}$. Then, \n",
    "> $$ (k * f)(\\mathbf{x}) := \\int_{\\mathbb{R}^2} k(\\mathbf{x} - \\mathbf{y}) f(\\mathbf{y}) \\mathrm{d} \\mathbf{y}. $$\n",
    "\n",
    "> **Example (Convolution on the Special Orthogonal Group)**\n",
    "> Let $f, k : \\operatorname{SO}(2) \\cong S^1 \\to \\mathbb{R}$. Then, \n",
    "> $$ (k * f)(\\theta) := \\int_{\\operatorname{SO}(2)} k(S^{-1} R_\\theta) f(S) \\mathrm{d} S = \\int_{S^1} k(\\theta - \\phi) f(\\phi) \\mathrm{d} \\phi. $$\n",
    "\n",
    "> **Example (Convolution on the Special Euclidean Group)**\n",
    "> Let $f, k : \\operatorname{SE}(2) \\cong \\mathbb{R}^2 \\times S^1 \\to \\mathbb{R}$. Then, \n",
    "> $$ (k * f)(\\mathbf{x}, \\theta) := \\int_{\\operatorname{SE}(2)} k((\\mathbf{y}, S)^{-1} (\\mathbf{x}, R_\\theta)) f(\\mathbf{y}, S) \\mathrm{d} \\mathbf{y} \\mathrm{d} S = \\int_{\\mathbb{R}^2 \\times S^1} k(R_{\\phi}^{-1} (\\mathbf{x} - \\mathbf{y}), \\theta - \\phi) f(\\mathbf{y}, \\phi) \\mathrm{d} \\mathbf{y} \\mathrm{d} \\phi. $$\n",
    "\n",
    "In the same way that normal convolutions - which are defined on functions on Euclidean space/translation group - are translation equivariant, group convolutions are equivariant to the corresponding group.\n",
    "> **Lemma (Group Convolutions are Equivariant)**\n",
    "> Let $G$ be a Lie group, let $f, k : G \\to \\mathbb{R}$ be functions thereon, and let $r \\in G$. Then, \n",
    "> $$ r (k * f) = k * (r f). $$\n",
    "_proof:_ We can simply rewrite:\n",
    "$$\\begin{split}\n",
    "r (k * f)(g) & := (k * f)(r^{-1} g) := \\int_G k(h^{-1} r^{-1} g) f(h) \\mathrm{d} h = \\int_G k((r h)^{-1} g) f(h) \\mathrm{d} h \\\\\n",
    "& = \\int_G k(q^{-1} g) f(r^{-1} q) \\mathrm{d} r^{-1}q \\overset{(1)}{=} \\int_G k(q^{-1} g) f(r^{-1} q) \\mathrm{d} q \\\\\n",
    "& =  (k * (r f))(g),\n",
    "\\end{split}$$\n",
    "where we used the left-invariance of the Haar measure in $(1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a6830d",
   "metadata": {},
   "source": [
    "In practice, we usually want our output to be an image again, so we need a way to equivariantly map orientation scores to images. We call this projection. In machine learning, we typically use max projection:\n",
    "> **Definition (Max Projection)** Let $f : \\operatorname{SE}(2) \\to \\mathbb{R}$. Then we define the _max projection_ of $f$\n",
    "> $$ \\operatorname{Proj} f(\\mathbf{x}, R) := \\max_{R \\in \\operatorname{SO}(2)} f(\\mathbf{x}, R). $$\n",
    "It is not hard to see that max projection is indeed equivariant:\n",
    "$$\\begin{split}\n",
    "(\\mathbf{x}, R) (\\operatorname{Proj} f)(\\mathbf{y}) & := \\operatorname{Proj} f((\\mathbf{x}, R)^{-1} \\mathbf{y}) = \\operatorname{Proj} f(R^{-1}(\\mathbf{y} - \\mathbf{x})) \\\\\n",
    "& = \\max_{S \\in \\operatorname{SO}(2)} f(R^{-1}(\\mathbf{y} - \\mathbf{x}), S) = \\max_{S \\in \\operatorname{SO}(2)} f(R^{-1}(\\mathbf{y} - \\mathbf{x}), R^{-1} S) = \\max_{S \\in \\operatorname{SO}(2)} (\\mathbf{x}, R) f(\\mathbf{y}, S) \\\\\n",
    "& = (\\operatorname{Proj} (\\mathbf{x}, R) f)(\\mathbf{y}).\n",
    "\\end{split}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b4b015",
   "metadata": {},
   "source": [
    "Hence, one way to make a roto-translation equivariant neural network architecture is as follows:\n",
    "1. Start with a lifting layer that maps images on $\\mathbb{R}^2$ to orientation scores on the group $\\operatorname{SE}(2)$. The lifting wavelets $\\psi$ are usually trained.\n",
    "2. Subsequently apply $\\operatorname{SE}(2)$ group convolutions and point-wise nonlinearities in alternating fashion.\n",
    "3. Project the orientation scores back to images using max projection.\n",
    "\n",
    "Neural networks with this architecture, which mirrors the classical multi-orientation image processing pipeline [2], are called Group equivariant Convolutional Neural Networks (G-CNNs).\n",
    "![Multi-orientation processing pipeline: first lift with the orientation score transform, then perform equivariant processing on the orientation scores, and finally project back down to an image.](content/multi-orientation_processing.png)\n",
    "\n",
    "For our classification task, the output should not be an image but a \"vector\" in $\\mathbb{P}_c := \\{(p_1, \\ldots, p_c) \\mid \\sum_{i = 1}^c p_i = 1, p_i \\geq 0\\}$, on which the group $\\operatorname{SE}(2)$ acts trivially. We can achieve this by adding additional layers to our network. The output images need to be invariantly converted to numbers, e.g. by taking the maximum over the image, which can then be combined in whatever manner we like. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd070698",
   "metadata": {},
   "source": [
    "Similar approaches can be taken for other affine groups, such as the translation-scaling group and the similarity group. One limitation of lifting is that it increases memory use: if we use $K$ discrete orientations, then the orientation score will use $K$ times as much memory as the image. This problem gets worse for higher dimensional groups, such as the similarity group $\\operatorname{SIM}(2) := \\mathbb{R}^2 \\rtimes (\\operatorname{SO}(2) \\times \\mathbb{R}_+)$, the group of translations, rotations and scalings: if we use $K$ discrete orientations and $M$ discrete scales, memory use will be $K \\times M$ times as large. In other words, memory use scales exponentially in the dimension of the group. Consequently, it is important to choose only the most important symmetries to integrate into the architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba42cac2",
   "metadata": {},
   "source": [
    "## Generalised Convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf686f76",
   "metadata": {},
   "source": [
    "In the previous section we introduced Group equivariant CNNs (G-CNNs), which first lift the data, then apply a succession of linear convolutions and (ReLU) point-wise nonlinearities in alternating fashion, and finally project the data back to an image. The alternating of linear and nonlinear operations turns out to be crucial for the expressivity of the model. One way to see this is with the following example:\n",
    "> **Example (Collapse of Linear Functions)** A composition of linear layers can only ever make a linear model, and so we cannot describe nonlinear models.\n",
    "> Additionally, there is an \"inefficiency\" in composing linear layers.\n",
    "> Let $A, B: \\mathbb{R}^n \\to \\mathbb{R}^n$ be linear. Then, $B A: \\mathbb{R}^n \\to \\mathbb{R}^n$ is also linear. \n",
    "> Then $B A$ can be described by $n \\times n$ parameters in a matrix, whereas together $A$ and $B$ have $2 \\times n \\times n$ parameters. \n",
    "\n",
    "Our research group developed a generalisation of G-CNNs, in which the (fixed) point-wise nonlinearities are replaced with (trainable) generalised convolutions.\n",
    "\n",
    "Recall the linear group convolution:\n",
    "$$ (k * f)(g) := \\int_G k(h^{-1} g) f(h) \\mathrm{d} h. $$\n",
    "Essentially, we place the kernel $k$ at the correct location $g$, multiply it point-wise with the function $f$, and then integrate that. In a generalised convolution, we change our notion of multiplication and integration. For example, for _morphological_ convolutions, multiplication becomes addition and integration becomes taking the infimum:\n",
    "$$ (k \\square f)(g) := \\inf_G (k(h^{-1} g) + f(h)). $$\n",
    "Morphological convolutions are the core operations in mathematical morphology, and can be used to perform _dilation_ and _erosion_:\n",
    "$$\\begin{align*}\n",
    "\\textrm{Dilation of $f$ by $k$: } & -(k \\square -f), \\\\\n",
    "\\textrm{Erosion of $f$ by $k$: } & (k \\square f).\n",
    "\\end{align*}$$\n",
    "Dilation expands light areas of $f$ according to the kernel $k$, whereas erosion expands the dark areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44eb119",
   "metadata": {},
   "outputs": [],
   "source": [
    "begin = 10\n",
    "end = 35\n",
    "data = torch.zeros(1, 1, 64, 64)\n",
    "data[0, 0, begin:end, begin:end] = 1.\n",
    "data[0, 0, -end:-begin, -end:-begin] = 1.\n",
    "kernel = morphological_kernel_r2_isotropic(torch.tensor([0.2]), 4, 0.65)\n",
    "dilated = -morphological_convolution_r2(-data, kernel)\n",
    "eroded = morphological_convolution_r2(data, kernel)\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
    "ax[0, 0].set_axis_off()\n",
    "ax[0, 1].set_axis_off()\n",
    "ax[1, 0].set_axis_off()\n",
    "ax[1, 1].set_axis_off()\n",
    "ax[0, 0].set_title(\"Input $f$\")\n",
    "ax[0, 1].set_title(\"Kernel $k$\")\n",
    "ax[1, 0].set_title(\"Dilated $-(k □ -f)$\")\n",
    "ax[1, 1].set_title(\"Eroded $k □ f$\")\n",
    "ax[0, 0].imshow(data.squeeze())\n",
    "cbar = ax[0, 1].imshow(kernel.squeeze())\n",
    "fig.colorbar(cbar, ax=ax[0, 1])\n",
    "ax[1, 0].imshow(dilated.squeeze())\n",
    "ax[1, 1].imshow(eroded.squeeze());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4aa84f",
   "metadata": {},
   "source": [
    "We can even go a step further, by using parametrised kernels such that the convolutions solve classical image processing PDEs. Such models are called PDE-based Group equivariant CNNs (PDE-G-CNNs) [3]. Here are some of the PDEs that are currently available in LieTorch, which is our implementation of PDE-G-CNNs.\n",
    "> **Example (Diffusion)** Diffusion, that is \n",
    "> $$\\partial_t U = \\Delta U,$$\n",
    "> is solved by a linear group convolution with the heat kernel, which is determined by a small number of parameters.\n",
    "\n",
    "> **Example (Dilation)** The dilation PDE,\n",
    "> $$\\partial_t U = \\Vert \\nabla U \\Vert^\\alpha,$$\n",
    "> is solved by a morphological group convolution with a kernel that is determined by small number of parameters.\n",
    "\n",
    "> **Example (Erosion)** The erosion PDE,\n",
    "> $$\\partial_t U = -\\Vert \\nabla U \\Vert^\\alpha,$$\n",
    "> is solved by a morphological group convolution with a kernel that is again determined by small number of parameters.\n",
    "\n",
    "> **Example (Convection)** The convection PDE,\n",
    "> $$\\partial_t U = -\\mathcal{A} U,$$\n",
    "> where $\\mathcal{A}$ is a left-invariant vector field, is solved by a linear group convolution with a correctly placed delta peak. \n",
    "\n",
    "Here is a brief overview comparing a typical layer in a (G-)CNN with a PDE-G-CNN layer. The PDE evolution consists of a composition of a number of PDEs, for example Convection-Dilation-Erosion (CDE).\n",
    "\n",
    "![Comparison of a traditional CNN layer and a PDE-G-CNN layer.](content/layer_comparison.webp)\n",
    "\n",
    "It has been shown in various works that PDE-G-CNNs can achieve performance competitive with e.g. CNNs, but with a large reduction in the number of model parameters. Additionally, they tend to be more data efficient, so they can be applied in situations where data is not abundant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711bdbce",
   "metadata": {},
   "source": [
    "## Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d69c5a2",
   "metadata": {},
   "source": [
    "This repository contains two trained models: a CNN and a roto-translation invariant PDE-G-CNN. The architectures can be found in the [`models.py`](models.py) module. The models have trained using the [`train.py`](train.py) script.\n",
    "\n",
    "The CNN is based on the classic LeNet-5 architecture. It consists of two convolutional layers with max-pooling and ReLU activation function, which are (approximately) translation equivariant, followed by three fully connected layers. Notably, the first fully connected layer is _not_ translation invariant, and we also do not have guaranteed translation invariance on the whole model.\n",
    "\n",
    "For our invariant network, we use a PDE-G-CNN. The first layer lifts the data. Then there are two layers of Convection-Dilation-Erosion PDE evolution, followed by a max projection layer. This leaves us with a collection of images. If we now immediately used a fully connected layer, that would break the equivariance. Hence, we max pool over each image, creating individual invariants. These can safely be used in a fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea59f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([0., 0.])\n",
    "theta_on_grid = torch.tensor([torch.pi / 2])\n",
    "R_on_grid = torch.tensor([\n",
    "    [torch.cos(theta_on_grid), -torch.sin(theta_on_grid)],\n",
    "    [torch.sin(theta_on_grid), torch.cos(theta_on_grid)]\n",
    "])\n",
    "theta_off_grid = torch.tensor([-0.682354])\n",
    "R_off_grid = torch.tensor([\n",
    "    [torch.cos(theta_off_grid), -torch.sin(theta_off_grid)],\n",
    "    [torch.sin(theta_off_grid), torch.cos(theta_off_grid)]\n",
    "])\n",
    "\n",
    "shoe_on_grid = transform(shoe, x, R_on_grid)\n",
    "shoe_off_grid = transform(shoe, x, R_off_grid)\n",
    "\n",
    "fig, ax = plt.subplots(3, 3, figsize=(15, 15))\n",
    "ax[0, 0].set_axis_off()\n",
    "ax[0, 1].set_axis_off()\n",
    "ax[0, 2].set_axis_off()\n",
    "ax[0, 0].set_title(\"Original\")\n",
    "ax[0, 1].set_title(\"On-grid rotation\")\n",
    "ax[0, 2].set_title(\"Off-grid rotation\")\n",
    "ax[0, 0].imshow(shoe.squeeze())\n",
    "ax[0, 1].imshow(shoe_on_grid.squeeze())\n",
    "ax[0, 2].imshow(shoe_off_grid.squeeze())\n",
    "plot_classification(shoe, pdegcnn, \"PDE-G-CNN\", ax[1, 0])\n",
    "plot_classification(shoe_on_grid, pdegcnn, \"PDE-G-CNN\", ax[1, 1])\n",
    "plot_classification(shoe_off_grid, pdegcnn, \"PDE-G-CNN\", ax[1, 2])\n",
    "plot_classification(shoe, cnn, \"CNN\", ax[2, 0])\n",
    "plot_classification(shoe_on_grid, cnn, \"CNN\", ax[2, 1])\n",
    "plot_classification(shoe_off_grid, cnn, \"CNN\", ax[2, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180e5179",
   "metadata": {},
   "source": [
    "This example of an \"Ankle boot\" is in its canonical orientation correctly classified by both the CNN and the equivariant PDE-G-CNN. However, when we rotate by $\\pi / 2$, the output of the PDE-G-CNN remains unchanged, while now the CNN confidently predicts the wrong class label. Rotations by $k \\cdot \\pi / 2$ are nice because they map the grid to itself. With other rotations, interpolation is necessary. Because of this, even the PDE-G-CNN is not exactly equivariant to off-grid rotations. However, as we can see in this example, it still fairly confidently predicts the right class, whereas the CNN yet again confidently predicts the wrong class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cdfc62",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "<a id=\"Smets2024GeometricProcessing\"></a>[1] B.M.N. Smets. Geometric Partial Differential Equations in Deep Learning and Image Processing (2024). <https://research.tue.nl/en/publications/geometric-partial-differential-equations-in-deep-learning-and-ima>\n",
    "\n",
    "```bib\n",
    "@phdthesis{smets2024geometric,\n",
    "  title={Geometric Partial Differential Equations in Deep Learning and Image Processing},\n",
    "  author={Smets, Bart M.N.},\n",
    "  year={2024},\n",
    "  isbn={978-90-386-6133-9},\n",
    "}\n",
    "```\n",
    "\n",
    "<a id=\"Sherry2025DiffusionSpace\"></a>[2] F.M. Sherry, K. Schaefer, R. Duits. Diffusion-Shock PDEs for Deep Learning on Position-Orientation Space. arXiv preprint (2025). <https://doi.org/10.48550/arXiv.2509.06405>\n",
    "\n",
    "```bib\n",
    "@article{sherry2025diffusion,\n",
    "  title={Diffusion-Shock PDEs for Deep Learning on Position-Orientation Space},\n",
    "  author={Sherry, F.M. and Schaefer, K. and Duits, R.},\n",
    "  journal={arXiv preprint},\n",
    "  year={2025},\n",
    "  doi={10.48550/arXiv.2509.06405},\n",
    "}\n",
    "```\n",
    "\n",
    "<a id=\"Smets2022PDENetworks\"></a>[3] B.M.N. Smets, J. Portegies, E.J. Bekkers, R. Duits. PDE-Based Group Equivariant Convolutional Neural Networks. J Math Imaging Vis (2022). <https://doi.org/10.1007/s10851-022-01114-x>\n",
    "\n",
    "```bib\n",
    "@article{smets2022pde,\n",
    "  title={PDE-based Group Equivariant Convolutional Neural Networks},\n",
    "  author={Smets, Bart M.N. and Portegies, Jim and Bekkers, Erik J. and Duits, Remco},\n",
    "  journal={Journal of Mathematical Imaging and Vision},\n",
    "  publisher={Springer},\n",
    "  year={2022},\n",
    "  doi={10.1007/s10851-022-01114-x},\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "equivariance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
