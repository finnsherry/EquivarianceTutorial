{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fb68fa1",
   "metadata": {},
   "source": [
    "# Equivariance Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e9d14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import affine_grid, grid_sample, pad, relu\n",
    "from torchvision.io import read_image\n",
    "import lietorch\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "extent = (-1, 1, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d55a197",
   "metadata": {},
   "outputs": [],
   "source": [
    "shoe = read_image(\"images/shoe.png\")[None, ...] / 255.\n",
    "dress = read_image(\"images/dress.png\")[None, ...] / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975665e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(image, x, A, padding=True):\n",
    "    \"\"\"Apply action (x, A) to image with circular padding.\"\"\"\n",
    "    B, C, H, W = image.shape\n",
    "    x = torch.tensor([-1., 1.]) * x\n",
    "    affine_matrix = torch.hstack((torch.linalg.inv(A.T), x[None, ...].T / 3))\n",
    "    if padding:\n",
    "        image = pad(image, (W, W, H, H), mode=\"circular\")\n",
    "        grid = affine_grid(affine_matrix[None, ...], (B, C, 3 * H, 3 * W), align_corners=False)\n",
    "        return grid_sample(image, grid, align_corners=False)[..., H:2*H, W:2*W]\n",
    "    else:\n",
    "        grid = affine_grid(affine_matrix[None, ...], (B, C, H, W), align_corners=False)\n",
    "        return grid_sample(image, grid, align_corners=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474be669",
   "metadata": {},
   "source": [
    "## Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fc9028",
   "metadata": {},
   "source": [
    "### Lie Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbda144d",
   "metadata": {},
   "source": [
    "> **Definition (Lie Group)** $G$ is a _Lie group_ if it is \n",
    "> 1. a _smooth manifold_ - so smooth and looks locally like $\\mathbb{R}^n$ - and\n",
    "> 2. a _group_ - we have a smooth, well-behaved product $\\cdot: G \\times G \\to G$.\n",
    "\n",
    "The most important Lie groups (imo) encode continuous symmetries on other spaces, with the group product simply given by composition.\n",
    "\n",
    "> **Example (Translation Group)**\n",
    "> The $n$-dimensional _translation group_ $\\mathbb{R}^n$ acts on Euclidean space $\\mathbb{R}^n$ by translation, namely\n",
    "> $$ (\\mathbf{x}, \\mathbf{y}) \\mapsto \\mathbf{x} + \\mathbf{y}, $$\n",
    "> and has group product\n",
    "> $$ (\\mathbf{x}, \\mathbf{y}) \\mapsto \\mathbf{x} + \\mathbf{y}. $$\n",
    "> Consequently, $\\mathbb{R}^n$ also acts on the functions on Euclidean space by\n",
    "> $$ (\\mathbf{x}, f) \\mapsto (\\mathbf{y} \\mapsto f(\\mathbf{y} - \\mathbf{x})). $$\n",
    "Of course, this is an incredibly boring example. \n",
    "Slightly less trivial is the following:\n",
    "> **Example (Special Orthogonal Group)**\n",
    "> The _special orthogonal group_ $\\operatorname{SO}(n)$ acts on Euclidean space $\\mathbb{R}^n$ by rotation, namely\n",
    "> $$ (R, \\mathbf{y}) \\mapsto R\\mathbf{y}, $$\n",
    "> and has group product\n",
    "> $$ (R, S) \\mapsto RS, $$\n",
    "> Consequently, $\\operatorname{SO}(n)$ also acts on the functions on Euclidean space by\n",
    "> $$ (R, f) \\mapsto (\\mathbf{x} \\mapsto f(R^{-1} \\mathbf{x})). $$\n",
    "Here, we represent the elements of $\\operatorname{SO}(n)$ as $n \\times n$ orthogonal matrices with determinant $1$. \n",
    "For example, in two dimensions the counter-clockwise rotation by angle $\\theta$ is given by\n",
    "$$ R = \\begin{pmatrix} \\cos(\\theta) & -\\sin(\\theta) \\\\\n",
    "\\sin(\\theta) & \\cos(\\theta) \\end{pmatrix}. $$\n",
    "\n",
    "In this example the group and the space that is acted on can no longer be identified.\n",
    "\n",
    "We get our favourite group by combining the two previous ones:\n",
    "> **Example (Special Euclidean Group)**\n",
    "> The _special Euclidean group_ $\\operatorname{SE}(n)$ acts on Euclidean space $\\mathbb{R}^n$ by roto-translation, namely\n",
    "> $$ ((\\mathbf{x}, R), \\mathbf{y}) \\mapsto \\mathbf{x} + R\\mathbf{y}, $$\n",
    "> and has group product\n",
    "> $$ ((\\mathbf{x}, R), (\\mathbf{y}, S)) \\mapsto (\\mathbf{x} + R\\mathbf{y}, RS). $$\n",
    "> Consequently, $\\operatorname{SE}(n)$ also acts on the functions on Euclidean space by\n",
    "> $$ (R, f) \\mapsto (\\mathbf{y} \\mapsto f(R^{-1}(\\mathbf{y} - \\mathbf{x}))). $$\n",
    "\n",
    "> _Remark_ The actions on functions are examples of so-called _group representations_, a term often encountered in the equivariance literature. For the sake of simplicity here we simply refer to them as actions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0ee49f",
   "metadata": {},
   "source": [
    "Finally, we have the most simple group action: doing nothing:\n",
    "> **Definition (Trivial Action)** Let $G$ be a Lie group and $X$ a set. Then we $G$ acts _trivially_ on $X$ if $g x = x$ for all $g \\in G$, $x \\in X$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb35a781",
   "metadata": {},
   "source": [
    "Many problems have inherent symmetries. For example, if we want to classify the object in an image, rotating the object shouldn't change the classification: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db71d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].set_title(\"Shoe\")\n",
    "ax[1].set_title(\"Still a shoe\")\n",
    "\n",
    "x = torch.tensor([0., 0.])\n",
    "R = torch.tensor([[1., 0.], [0., 1.]])\n",
    "ax[0].imshow(transform(shoe, x, R).squeeze(), extent=extent)\n",
    "\n",
    "# Your roto-translation here ⬇️\n",
    "x = torch.tensor([0., 0.])\n",
    "theta = torch.tensor([0.])\n",
    "R = torch.tensor([\n",
    "    [torch.cos(theta), -torch.sin(theta)],\n",
    "    [torch.sin(theta), torch.cos(theta)]\n",
    "])\n",
    "ax[1].imshow(transform(shoe, x, R).squeeze(), extent=extent);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988d66dc",
   "metadata": {},
   "source": [
    "Lie groups give us a mathematically formal way of thinking about these symmetries. In particular, we can now define _equivariance_, which is the formal way of describing that an operator preserves a symmetry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2c953e",
   "metadata": {},
   "source": [
    "### Equivariance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de73448c",
   "metadata": {},
   "source": [
    "> **Definition (Equivariance)** Let $G$ be a Lie group acting on $U$ and $V$. \n",
    "> $\\Phi: U \\to V$ is called _equivariant_ if it commutes with the group actions, i.e.\n",
    "> $$ \\Phi \\circ g = g \\circ \\Phi, $$\n",
    "> for all $g \\in G$.\n",
    "\n",
    "If the action on $V$ is trivial, then we say $\\Phi$ is _invariant_. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a405703",
   "metadata": {},
   "source": [
    "Let's work this out for our classification problem.\n",
    "- We have a classifier $\\Phi: \\mathbb{L}_2(\\mathbb{R}^2) \\to \\{1, \\ldots, c\\}$, where $c$ is the number of classes.\n",
    "- We can see images as functions on $\\mathbb{R}^2$, on which the Lie group $\\operatorname{SE}(2)$ acts by roto-translation: $(\\mathbf{x}, R) f(\\vec{y}) = f(R^{-1} (\\mathbf{y} - \\mathbf{x}))$.\n",
    "- $\\operatorname{SE}(2)$ acts trivially on the range $\\{1, \\ldots, c\\}$, so we have $(\\mathbf{x}, R) k = k$ for all $k \\in \\{1, \\ldots, c\\}$.\n",
    "\n",
    "Then the classifier is invariant if $\\Phi(f) \\circ g = g \\circ \\Phi(f) = \\Phi(f)$ for all $g \\in \\operatorname{SE}(2)$ and images $f: \\mathbb{R}^2 \\to \\mathbb{R}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9118f875",
   "metadata": {},
   "source": [
    "In this problem invariance is clearly a desirable property. But how would we go about constructing an invariant classifier? \n",
    "\n",
    "We could train a normal convolutional neural network, and hope that it learns to be invariant. This is highly unlikely, unless we perform _data augmentation_ - - and even then there are no guarantees.\n",
    "\n",
    "Alternatively, we could construct a neural network architecture that is inherently invariant. For this, we can make use of the following result:\n",
    "> **Lemma (Composition of Equivariant Maps)** Let $G$ be a Lie group acting on $U$, $V$, and $W$. Suppose $\\Phi: U \\to V$ and $\\Psi: V \\to W$ are equivariant. Then, their composition $\\Psi \\circ \\Phi: U \\to W$ is also equivariant. \n",
    "\n",
    "_proof_: Simply note that $\\Psi \\circ \\Phi \\circ g = \\Psi \\circ g \\circ \\Phi = g \\circ \\Psi \\circ \\Phi$.\n",
    "\n",
    "Hence, we can make an equivariant neural network architecture by composing equivariant layers. A typical layer in a neural network consists of the composition of something linear (e.g. matrix multiplication, convolution, linear combinations) with something nonlinear (e.g. activation function, normalisation). Common nonlinearities such as the ReLU activation function and batch normalisation act point-wise; it is not hard to see that these are equivariant operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b233b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].set_axis_off()\n",
    "ax[1].set_axis_off()\n",
    "ax[0].set_title(\"ReLUed Shoe\")\n",
    "ax[1].set_title(\"Still a ReLUed shoe\")\n",
    "ax[0].imshow(relu(shoe - 0.5).squeeze())\n",
    "x = torch.tensor([0., 0.])\n",
    "theta = torch.tensor([-0.862364]) # Random number\n",
    "R = torch.tensor([\n",
    "    [torch.cos(theta), -torch.sin(theta)],\n",
    "    [torch.sin(theta), torch.cos(theta)]\n",
    "])\n",
    "ax[1].imshow(relu(transform(shoe, x, R, padding=False) - 0.5).squeeze());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fc8457",
   "metadata": {},
   "source": [
    "### Lifting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711bdbce",
   "metadata": {},
   "source": [
    "## Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67189036",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "equivariance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
