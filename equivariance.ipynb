{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fb68fa1",
   "metadata": {},
   "source": [
    "# Equivariance Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e9d14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import affine_grid, grid_sample, pad, relu\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import Normalize\n",
    "from models import CNN, PDEGCNN\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "extent = (-1, 1, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d55a197",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = Normalize(0.5, 0.5)\n",
    "shoe = norm(read_image(\"images/shoe.png\")[None, ...] / 255.)\n",
    "dress = norm(read_image(\"images/dress.png\")[None, ...] / 255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a06c21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_to_label(logits):\n",
    "    labels = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "    return labels[logits.argmax()]\n",
    "\n",
    "cnn_model = CNN()\n",
    "cnn_model.load_state_dict(torch.load(\"CNN.pth\", weights_only=True))\n",
    "cnn_model.eval()\n",
    "\n",
    "def cnn(image):\n",
    "    print(cnn_model.training)\n",
    "    logits = cnn_model(image)\n",
    "    return logits_to_label(logits), logits\n",
    "\n",
    "pdegcnn_model = PDEGCNN()\n",
    "pdegcnn_model.load_state_dict(torch.load(\"PDEGCNN.pth\", weights_only=True))\n",
    "pdegcnn_model.eval()\n",
    "\n",
    "def pdegcnn(image):\n",
    "    print(pdegcnn_model.training)\n",
    "    logits = pdegcnn_model(image)\n",
    "    return logits_to_label(logits), logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975665e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(image, x, A, padding=True):\n",
    "    \"\"\"Apply action (x, A) to image with circular padding.\"\"\"\n",
    "    B, C, H, W = image.shape\n",
    "    x = torch.tensor([-1., 1.]) * x\n",
    "    affine_matrix = torch.hstack((torch.linalg.inv(A.T), x[None, ...].T / 3))\n",
    "    if padding:\n",
    "        image = pad(image, (W, W, H, H), mode=\"circular\")\n",
    "        grid = affine_grid(affine_matrix[None, ...], (B, C, 3 * H, 3 * W), align_corners=False)\n",
    "        return grid_sample(image, grid, align_corners=False)[..., H:2*H, W:2*W]\n",
    "    else:\n",
    "        grid = affine_grid(affine_matrix[None, ...], (B, C, H, W), align_corners=False)\n",
    "        return grid_sample(image, grid, align_corners=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474be669",
   "metadata": {},
   "source": [
    "## Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fc9028",
   "metadata": {},
   "source": [
    "### Lie Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbda144d",
   "metadata": {},
   "source": [
    "> **Definition (Lie Group)** $G$ is a _Lie group_ if it is \n",
    "> 1. a _smooth manifold_ - so smooth and looks locally like $\\mathbb{R}^n$ - and\n",
    "> 2. a _group_ - we have a smooth, well-behaved product $\\cdot: G \\times G \\to G$.\n",
    "\n",
    "The most important Lie groups (imo) encode continuous symmetries on other spaces, with the group product simply given by composition.\n",
    "\n",
    "> **Example (Translation Group)**\n",
    "> The $n$-dimensional _translation group_ $\\mathbb{R}^n$ acts on Euclidean space $\\mathbb{R}^n$ by translation, namely\n",
    "> $$ (\\mathbf{x}, \\mathbf{y}) \\mapsto \\mathbf{x} + \\mathbf{y}, $$\n",
    "> and has group product\n",
    "> $$ (\\mathbf{x}, \\mathbf{y}) \\mapsto \\mathbf{x} + \\mathbf{y}. $$\n",
    "> Consequently, $\\mathbb{R}^n$ also acts on the functions on Euclidean space by\n",
    "> $$ (\\mathbf{x}, f) \\mapsto (\\mathbf{y} \\mapsto f(\\mathbf{y} - \\mathbf{x})). $$\n",
    "Of course, this is an incredibly boring example. \n",
    "Slightly less trivial is the following:\n",
    "> **Example (Special Orthogonal Group)**\n",
    "> The _special orthogonal group_ $\\operatorname{SO}(n)$ acts on Euclidean space $\\mathbb{R}^n$ by rotation, namely\n",
    "> $$ (R, \\mathbf{y}) \\mapsto R\\mathbf{y}, $$\n",
    "> and has group product\n",
    "> $$ (R, S) \\mapsto RS, $$\n",
    "> Consequently, $\\operatorname{SO}(n)$ also acts on the functions on Euclidean space by\n",
    "> $$ (R, f) \\mapsto (\\mathbf{x} \\mapsto f(R^{-1} \\mathbf{x})). $$\n",
    "Here, we represent the elements of $\\operatorname{SO}(n)$ as $n \\times n$ orthogonal matrices with determinant $1$. \n",
    "For example, in two dimensions the counter-clockwise rotation by angle $\\theta$ is given by\n",
    "$$ R = \\begin{pmatrix} \\cos(\\theta) & -\\sin(\\theta) \\\\\n",
    "\\sin(\\theta) & \\cos(\\theta) \\end{pmatrix}. $$\n",
    "\n",
    "In this example the group and the space that is acted on can no longer be identified.\n",
    "\n",
    "We get our favourite group by combining the two previous ones:\n",
    "> **Example (Special Euclidean Group)**\n",
    "> The _special Euclidean group_ $\\operatorname{SE}(n)$ acts on Euclidean space $\\mathbb{R}^n$ by roto-translation, namely\n",
    "> $$ ((\\mathbf{x}, R), \\mathbf{y}) \\mapsto \\mathbf{x} + R\\mathbf{y}, $$\n",
    "> and has group product\n",
    "> $$ ((\\mathbf{x}, R), (\\mathbf{y}, S)) \\mapsto (\\mathbf{x} + R\\mathbf{y}, RS). $$\n",
    "> Consequently, $\\operatorname{SE}(n)$ also acts on the functions on Euclidean space by\n",
    "> $$ (R, f) \\mapsto (\\mathbf{y} \\mapsto f(R^{-1}(\\mathbf{y} - \\mathbf{x}))). $$\n",
    "\n",
    "> _Remark_ The actions on functions are examples of so-called _group representations_, a term often encountered in the equivariance literature. For the sake of simplicity here we simply refer to them as actions.\n",
    "\n",
    "Finally, we have the most simple group action: doing nothing:\n",
    "> **Definition (Trivial Action)** Let $G$ be a Lie group and $X$ a set. Then we $G$ acts _trivially_ on $X$ if $g x = x$ for all $g \\in G$, $x \\in X$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb35a781",
   "metadata": {},
   "source": [
    "Many problems have inherent symmetries. For example, if we want to classify the object in an image, rotating the object shouldn't change the classification: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db71d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].set_title(\"Shoe\")\n",
    "ax[1].set_title(\"Still a shoe\")\n",
    "\n",
    "x = torch.tensor([0., 0.])\n",
    "R = torch.tensor([[1., 0.], [0., 1.]])\n",
    "ax[0].imshow(transform(shoe, x, R).squeeze(), extent=extent)\n",
    "\n",
    "# Your roto-translation here ⬇️\n",
    "x = torch.tensor([0., 0.])\n",
    "theta = torch.tensor([0.])\n",
    "R = torch.tensor([\n",
    "    [torch.cos(theta), -torch.sin(theta)],\n",
    "    [torch.sin(theta), torch.cos(theta)]\n",
    "])\n",
    "ax[1].imshow(transform(shoe, x, R).squeeze(), extent=extent);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988d66dc",
   "metadata": {},
   "source": [
    "Lie groups give us a mathematically formal way of thinking about these symmetries. In particular, we can now define _equivariance_, which in essence is a symmetry preservation property."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2c953e",
   "metadata": {},
   "source": [
    "### Equivariance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de73448c",
   "metadata": {},
   "source": [
    "> **Definition (Equivariance)** Let $G$ be a Lie group acting on $U$ and $V$. \n",
    "> $\\Phi: U \\to V$ is called _equivariant_ if it commutes with the group actions, i.e.\n",
    "> $$ \\Phi \\circ g = g \\circ \\Phi, $$\n",
    "> for all $g \\in G$.\n",
    "\n",
    "If the action on $V$ is trivial, then we say $\\Phi$ is _invariant_. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a405703",
   "metadata": {},
   "source": [
    "Let's work this out for our classification problem.\n",
    "- We can see images as functions on $\\mathbb{R}^2$, on which the Lie group $\\operatorname{SE}(2)$ acts by roto-translation: $(\\mathbf{x}, R) f(\\vec{y}) = f(R^{-1} (\\mathbf{y} - \\mathbf{x}))$.\n",
    "- We have a classifier $\\Phi$ which maps an image $f: \\mathbb{R}^2 \\to \\mathbb{R}$ to a label $k \\in \\{1, \\ldots, c\\}$, where $c$ is the number of classes.\n",
    "- $\\operatorname{SE}(2)$ acts trivially on the range $\\{1, \\ldots, c\\}$, so we have $(\\mathbf{x}, R) k = k$ for all $k \\in \\{1, \\ldots, c\\}$.\n",
    "\n",
    "Then the classifier is invariant if $\\Phi(f) \\circ g = g \\circ \\Phi(f) = \\Phi(f)$ for all $g \\in \\operatorname{SE}(2)$ and images $f: \\mathbb{R}^2 \\to \\mathbb{R}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9118f875",
   "metadata": {},
   "source": [
    "In this problem invariance is clearly a desirable property. But how would we go about constructing an invariant classifier? \n",
    "\n",
    "We could train a normal convolutional neural network, and hope that it learns to be invariant. This is highly unlikely, unless we perform _data augmentation_ - - and even then there are no guarantees.\n",
    "\n",
    "Alternatively, we could construct a neural network architecture that is inherently invariant. For this, we can make use of the following result:\n",
    "> **Lemma (Composition of Equivariant Maps)** Let $G$ be a Lie group acting on $U$, $V$, and $W$. Suppose $\\Phi: U \\to V$ and $\\Psi: V \\to W$ are equivariant. Then, their composition $\\Psi \\circ \\Phi: U \\to W$ is also equivariant. \n",
    "\n",
    "_proof_: Simply note that $\\Psi \\circ \\Phi \\circ g = \\Psi \\circ g \\circ \\Phi = g \\circ \\Psi \\circ \\Phi$.\n",
    "\n",
    "Hence, we can make an equivariant neural network architecture by composing equivariant layers. A typical layer in a neural network consists of the composition of something linear (e.g. matrix multiplication, convolution, linear combinations) with something nonlinear (e.g. activation function, normalisation). Common nonlinearities such as the ReLU activation function and batch normalisation act point-wise; it is not hard to see that such point-wise operations are equivariant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b233b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].set_axis_off()\n",
    "ax[1].set_axis_off()\n",
    "ax[0].set_title(\"ReLUed Shoe\")\n",
    "ax[1].set_title(\"Still a ReLUed shoe\")\n",
    "ax[0].imshow(relu(shoe - 0.5).squeeze())\n",
    "x = torch.tensor([0., 0.])\n",
    "theta = torch.tensor([-0.862364]) # Random number\n",
    "R = torch.tensor([\n",
    "    [torch.cos(theta), -torch.sin(theta)],\n",
    "    [torch.sin(theta), torch.cos(theta)]\n",
    "])\n",
    "ax[1].imshow(relu(transform(shoe, x, R, padding=False) - 0.5).squeeze());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fc8457",
   "metadata": {},
   "source": [
    "### Lifting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711bdbce",
   "metadata": {},
   "source": [
    "## Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d69c5a2",
   "metadata": {},
   "source": [
    "This repository contains two trained models: a CNN and a roto-translation invariant PDE-G-CNN. The architectures can be found in the [`models.py`](models.py) module. The models have trained using the [`train.py`](train.py) script.\n",
    "\n",
    "The CNN is based on the classic LeNet-5 architecture. It consists of two convolutional layers with max-pooling, which are (approximately) translation equivariant, followed by three fully connected layers. Notably, the first fully connected layer is _not_ translation invariant, and we also do not have guaranteed translation invariance on the whole model.\n",
    "\n",
    "PDE-based Group equivariant CNNs (PDE-G-CNNs) [1]. They are closely related to Group equivariant CNNs (G-CNNs)\n",
    "\n",
    "![Comparison of a traditional CNN layer and a PDE-G-CNN layer.](layer_comparison.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b3c260",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([0., 0.])\n",
    "theta = torch.tensor([torch.pi/2])\n",
    "R = torch.tensor([\n",
    "    [torch.cos(theta), -torch.sin(theta)],\n",
    "    [torch.sin(theta), torch.cos(theta)]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457d9c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(shoe.squeeze())\n",
    "ax[1].imshow(transform(shoe, x, R).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edba450c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdegcnn_model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afb20ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    print(pdegcnn(shoe.to(\"cuda\")))\n",
    "    print(pdegcnn(torch.rot90(shoe, dims=(-2, -1)).to(\"cuda\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e23b37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shoe_cuda = shoe.to(\"cuda\")\n",
    "model_cuda = pdegcnn_model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bfed88",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    cbar = ax.imshow((\n",
    "        torch.rot90(model_cuda(shoe_cuda), dims=(-2, -1)) - \n",
    "        model_cuda(torch.rot90(shoe_cuda, dims=(-2, -1)))).abs().sum(1).squeeze().cpu())\n",
    "    fig.colorbar(cbar, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b050b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    cbar = ax.imshow((\n",
    "        transform(pdegcnn_model(shoe), x, R) - \n",
    "        pdegcnn_model(transform(shoe, x, R))).abs().sum(1).squeeze())\n",
    "    fig.colorbar(cbar, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c76aefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    print(cnn(shoe)[0], cnn(transform(shoe, x, R))[0])\n",
    "    print(cnn(shoe)[1])\n",
    "    print(cnn(transform(shoe, x, R))[1])\n",
    "    print(pdegcnn(shoe)[0], pdegcnn(transform(shoe, x, R))[0])\n",
    "    print(pdegcnn(shoe)[1])\n",
    "    print(pdegcnn(transform(shoe, x, R))[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cdfc62",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "<a id=\"Smets2022PDENetworks\"></a>[1] B.M.N. Smets, J. Portegies, E.J. Bekkers, R. Duits. PDE-Based Group Equivariant Convolutional Neural Networks. J Math Imaging Vis (2022). <https://doi.org/10.1007/s10851-022-01114-x>\n",
    "\n",
    "```bib\n",
    "@article{smets2022pde,\n",
    "  title={PDE-based Group Equivariant Convolutional Neural Networks},\n",
    "  author={Smets, Bart M.N. and Portegies, Jim and Bekkers, Erik J. and Duits, Remco},\n",
    "  journal={Journal of Mathematical Imaging and Vision},\n",
    "  publisher={Springer},\n",
    "  year={2022},\n",
    "  doi={10.1007/s10851-022-01114-x},\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad50313e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-lietorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
