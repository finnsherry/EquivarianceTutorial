{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fb68fa1",
   "metadata": {},
   "source": [
    "# Equivariance Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510f9415",
   "metadata": {},
   "source": [
    "In this tutorial, we will discuss the concept of _equivariance_. As a model problem, we consider classifying FashionMNIST, though the concepts can be easily extended to other image processing such as segmentation and denoising (and also tasks that don't involve images...). FashionMNIST is a dataset of thumbnails of items of clothing from Zalando, accompanied with a label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e9d14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import affine_grid, grid_sample, relu, softmax, pad, conv2d\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import Normalize\n",
    "from models import CNN, PDEGCNN\n",
    "from lietorch.nn.m2 import LiftM2Cakewavelets\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.rcParams['figure.constrained_layout.use'] = True\n",
    "\n",
    "norm = Normalize(0.5, 0.5)\n",
    "shoe = norm(read_image(\"images/shoe.png\")[None, ...] / 255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc0bb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "ax.set_axis_off()\n",
    "ax.set_title(\"Shoe\")\n",
    "ax.imshow(shoe.squeeze());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a06c21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "\n",
    "def logits_to_label(logits):\n",
    "    return labels[logits.argmax()]\n",
    "\n",
    "cnn_model = CNN()\n",
    "cnn_model.load_state_dict(torch.load(\"CNN.pth\", weights_only=True))\n",
    "cnn_model.eval()\n",
    "\n",
    "def cnn(image):\n",
    "    with torch.no_grad():\n",
    "        logits = cnn_model(image)[0]\n",
    "    return logits_to_label(logits), softmax(logits, dim=-1)\n",
    "\n",
    "pdegcnn_model = PDEGCNN()\n",
    "pdegcnn_model.load_state_dict(torch.load(\"PDEGCNN.pth\", weights_only=True))\n",
    "pdegcnn_model.eval()\n",
    "\n",
    "def pdegcnn(image):\n",
    "    with torch.no_grad():\n",
    "        logits = pdegcnn_model(image)[0]\n",
    "    return logits_to_label(logits), softmax(logits, dim=-1)\n",
    "\n",
    "def plot_classification(image, model, model_name, ax):\n",
    "    probs = model(image)[1]\n",
    "    colours = len(labels) * [\"tab:blue\"]\n",
    "    colours[probs.argmax()] = \"tab:red\"\n",
    "    ax.bar(labels, probs, color=colours)\n",
    "    ax.set_title(model_name)\n",
    "    ax.set_xlabel(\"Class\")\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_xticks(range(len(labels)))\n",
    "    ax.set_xticklabels(labels, rotation=45, ha='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975665e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(image, x, A):\n",
    "    \"\"\"Apply action (x, A) to image with replication padding.\"\"\"\n",
    "    B, C, H, W = image.shape\n",
    "    x = torch.tensor([-1., 1.]) * x\n",
    "    affine_matrix = torch.hstack((torch.linalg.inv(A.T), x[None, ...].T))\n",
    "    grid = affine_grid(affine_matrix[None, ...], (B, C, H, W), align_corners=False)\n",
    "    return grid_sample(image, grid, padding_mode=\"border\", align_corners=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474be669",
   "metadata": {},
   "source": [
    "## Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fc9028",
   "metadata": {},
   "source": [
    "### Lie Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbda144d",
   "metadata": {},
   "source": [
    "> **Definition (Lie Group)** $G$ is a _Lie group_ if it is \n",
    "> 1. a _smooth manifold_ - so smooth and looks locally like $\\mathbb{R}^n$ - and\n",
    "> 2. a _group_ - we have a smooth, well-behaved product $\\cdot: G \\times G \\to G$.\n",
    "\n",
    "The most important Lie groups (imo) encode continuous symmetries on other spaces, with the group product simply given by composition.\n",
    "\n",
    "> **Example (Translation Group)**\n",
    "> The $n$-dimensional _translation group_ $\\mathbb{R}^n$ acts on Euclidean space $\\mathbb{R}^n$ by translation, namely\n",
    "> $$ (\\mathbf{x}, \\mathbf{y}) \\mapsto \\mathbf{x} + \\mathbf{y}, $$\n",
    "> and has group product\n",
    "> $$ (\\mathbf{x}, \\mathbf{y}) \\mapsto \\mathbf{x} + \\mathbf{y}. $$\n",
    "> Consequently, $\\mathbb{R}^n$ also acts on the functions on Euclidean space by\n",
    "> $$ (\\mathbf{x}, f) \\mapsto (\\mathbf{y} \\mapsto f(\\mathbf{y} - \\mathbf{x})). $$\n",
    "Of course, this is an incredibly boring example. \n",
    "Slightly less trivial is the following:\n",
    "> **Example (Special Orthogonal Group)**\n",
    "> The _special orthogonal group_ $\\operatorname{SO}(n)$ acts on Euclidean space $\\mathbb{R}^n$ by rotation, namely\n",
    "> $$ (R, \\mathbf{y}) \\mapsto R\\mathbf{y}, $$\n",
    "> and has group product\n",
    "> $$ (R, S) \\mapsto RS, $$\n",
    "> Consequently, $\\operatorname{SO}(n)$ also acts on the functions on Euclidean space by\n",
    "> $$ (R, f) \\mapsto (\\mathbf{x} \\mapsto f(R^{-1} \\mathbf{x})). $$\n",
    "Here, we represent the elements of $\\operatorname{SO}(n)$ as $n \\times n$ orthogonal matrices with determinant $1$. \n",
    "For example, in two dimensions the counter-clockwise rotation by angle $\\theta$ is given by\n",
    "$$ R = \\begin{pmatrix} \\cos(\\theta) & -\\sin(\\theta) \\\\\n",
    "\\sin(\\theta) & \\cos(\\theta) \\end{pmatrix}. $$\n",
    "\n",
    "In this example the group and the space that is acted on can no longer be identified.\n",
    "\n",
    "We get our favourite group by combining the two previous ones:\n",
    "> **Example (Special Euclidean Group)**\n",
    "> The _special Euclidean group_ $\\operatorname{SE}(n) := \\mathbb{R}^n \\rtimes \\operatorname{SO}(n)$ acts on Euclidean space $\\mathbb{R}^n$ by roto-translation, namely\n",
    "> $$ ((\\mathbf{x}, R), \\mathbf{y}) \\mapsto \\mathbf{x} + R\\mathbf{y}, $$\n",
    "> and has group product\n",
    "> $$ ((\\mathbf{x}, R), (\\mathbf{y}, S)) \\mapsto (\\mathbf{x} + R\\mathbf{y}, RS). $$\n",
    "> Consequently, $\\operatorname{SE}(n)$ also acts on the functions on Euclidean space by\n",
    "> $$ (R, f) \\mapsto (\\mathbf{y} \\mapsto f(R^{-1}(\\mathbf{y} - \\mathbf{x}))). $$\n",
    "\n",
    "> _Remark_ The actions on functions are examples of so-called _group representations_, a term often encountered in the equivariance literature. For the sake of simplicity here we simply refer to them as actions.\n",
    "\n",
    "Finally, we have the most simple group action: doing nothing:\n",
    "> **Definition (Trivial Action)** Let $G$ be a Lie group and $X$ a set. Then we $G$ acts _trivially_ on $X$ if $g x = x$ for all $g \\in G$, $x \\in X$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb35a781",
   "metadata": {},
   "source": [
    "Many problems have inherent symmetries. For example, if we want to classify the object in an image, rotating the object shouldn't change the classification: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db71d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].set_axis_off()\n",
    "ax[1].set_axis_off()\n",
    "ax[0].set_title(\"Shoe\")\n",
    "ax[1].set_title(\"Still a shoe\")\n",
    "\n",
    "x = torch.tensor([0., 0.])\n",
    "R = torch.tensor([[1., 0.], [0., 1.]])\n",
    "ax[0].imshow(transform(shoe, x, R).squeeze())\n",
    "\n",
    "# Your roto-translation here ⬇️\n",
    "x = torch.tensor([0., 0.])\n",
    "theta = torch.tensor([0.8712346])\n",
    "R = torch.tensor([\n",
    "    [torch.cos(theta), -torch.sin(theta)],\n",
    "    [torch.sin(theta), torch.cos(theta)]\n",
    "])\n",
    "ax[1].imshow(transform(shoe, x, R).squeeze());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988d66dc",
   "metadata": {},
   "source": [
    "Lie groups give us a mathematically formal way of thinking about these symmetries. In particular, we can now define _equivariance_, which in essence is a symmetry preservation property."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2c953e",
   "metadata": {},
   "source": [
    "### Equivariance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de73448c",
   "metadata": {},
   "source": [
    "> **Definition (Equivariance)** Let $G$ be a Lie group acting on $U$ and $V$. \n",
    "> $\\Phi: U \\to V$ is called _equivariant_ if it commutes with the group actions, i.e.\n",
    "> $$ \\Phi \\circ g = g \\circ \\Phi, $$\n",
    "> for all $g \\in G$.\n",
    "\n",
    "If the action on $V$ is trivial, then we say $\\Phi$ is _invariant_. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a405703",
   "metadata": {},
   "source": [
    "Let's work this out for our classification problem.\n",
    "- We can see images as functions on $\\mathbb{R}^2$, on which the Lie group $\\operatorname{SE}(2)$ acts by roto-translation: $(\\mathbf{x}, R) f(\\vec{y}) = f(R^{-1} (\\mathbf{y} - \\mathbf{x}))$.\n",
    "- We have a classifier $\\Phi$ which maps an image $f: \\mathbb{R}^2 \\to \\mathbb{R}$ to a probability distribution $p \\in \\mathbb{P}_c := \\{(p_1, \\ldots, p_c) \\mid \\sum_{i = 1}^c p_i = 1, p_i \\geq 0\\}$ over labels $\\{1, \\ldots, c\\}$, where $c$ is the number of classes.\n",
    "- $\\operatorname{SE}(2)$ acts trivially on the range $\\mathbb{P}_c$, so we have $(\\mathbf{x}, R) p = p$ for all $p \\in \\mathbb{P}_c$.\n",
    "\n",
    "Then the classifier is invariant if $\\Phi(f) \\circ g = g \\circ \\Phi(f) = \\Phi(f)$ for all $g \\in \\operatorname{SE}(2)$ and images $f: \\mathbb{R}^2 \\to \\mathbb{R}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9118f875",
   "metadata": {},
   "source": [
    "In this problem invariance is clearly a desirable property. But how would we go about constructing an invariant classifier? \n",
    "\n",
    "We could train a normal convolutional neural network, and hope that it learns to be invariant. This is highly unlikely, unless we perform _data augmentation_, and even then there are no guarantees.\n",
    "\n",
    "Alternatively, we could construct a neural network architecture that is inherently invariant. For this, we can make use of the following result:\n",
    "> **Lemma (Composition of Equivariant Maps)** Let $G$ be a Lie group acting on $U$, $V$, and $W$. Suppose $\\Phi: U \\to V$ and $\\Psi: V \\to W$ are equivariant. Then, their composition $\\Psi \\circ \\Phi: U \\to W$ is also equivariant. \n",
    "\n",
    "_proof_: Simply note that $\\Psi \\circ \\Phi \\circ g = \\Psi \\circ g \\circ \\Phi = g \\circ \\Psi \\circ \\Phi$.\n",
    "\n",
    "Hence, we can make an equivariant neural network architecture by composing equivariant layers. A typical layer in a neural network consists of the composition of something linear (e.g. matrix multiplication, convolution, linear combinations) with something nonlinear (e.g. activation function, normalisation). Common nonlinearities such as the ReLU activation function and batch normalisation act point-wise; it is not hard to see that such point-wise operations are equivariant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b233b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([0., 0.])\n",
    "theta = torch.tensor([-0.862364]) # Random number\n",
    "R = torch.tensor([\n",
    "    [torch.cos(theta), -torch.sin(theta)],\n",
    "    [torch.sin(theta), torch.cos(theta)]\n",
    "])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].set_axis_off()\n",
    "ax[1].set_axis_off()\n",
    "ax[0].set_title(\"Transform before ReLU\")\n",
    "ax[1].set_title(\"ReLU before Transform\")\n",
    "ax[0].imshow(relu(transform(shoe, x, R)).squeeze())\n",
    "ax[1].imshow(transform(relu(shoe), x, R).squeeze());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cffd30",
   "metadata": {},
   "source": [
    "We're working with images in this tutorial; convolutions are a natural choice for the linear part. In a convolutional layer an image is convolved/cross-correlated with a trainable filter (Fig. 5.3 from [1]):\n",
    "![Schematic depiction of a convolution.](convolution.png)\n",
    "Convolutional layers are translation equivariant: if you shift the input image, the output is shifted accordingly (up to boundary effects...):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8274b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = torch.randn(1, 1, 3, 3)\n",
    "\n",
    "k = 4 # number of pixels to shift\n",
    "padding = k + 1 # deal with boundary issues\n",
    "x = torch.tensor([k * (2 / (shoe.shape[-1] + 2 * padding)), 0.])\n",
    "theta = torch.tensor([0.])\n",
    "R = torch.tensor([\n",
    "    [torch.cos(theta), -torch.sin(theta)],\n",
    "    [torch.sin(theta), torch.cos(theta)]\n",
    "])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].set_axis_off()\n",
    "ax[1].set_axis_off()\n",
    "ax[0].set_title(\"Shift before Convolution\")\n",
    "ax[1].set_title(\"Convolution before Shift\")\n",
    "ax[0].imshow(conv2d(transform(pad(shoe, 4*[padding], mode=\"replicate\"), x, R), kernel, torch.tensor([0.])).squeeze())\n",
    "ax[1].imshow(transform(conv2d(pad(shoe, 4*[padding], mode=\"replicate\"), kernel, torch.tensor([0.])), x, R).squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dda5ed",
   "metadata": {},
   "source": [
    "However, convolutional layers typically won't be rotation equivariant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002a62e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([0., 0.])\n",
    "theta = torch.tensor([torch.pi/2])\n",
    "R = torch.tensor([\n",
    "    [torch.cos(theta), -torch.sin(theta)],\n",
    "    [torch.sin(theta), torch.cos(theta)]\n",
    "])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].set_axis_off()\n",
    "ax[1].set_axis_off()\n",
    "ax[0].set_title(\"Rotate before Convolution\")\n",
    "ax[1].set_title(\"Convolution before Rotate\")\n",
    "ax[0].imshow(conv2d(transform(shoe, x, R), kernel, torch.tensor([0.])).squeeze())\n",
    "ax[1].imshow(transform(conv2d(shoe, kernel, torch.tensor([0.])), x, R).squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61dc677",
   "metadata": {},
   "source": [
    "Indeed, convolutions are rotation equivariant if and only if the kernel is isotropic. We can achieve this by averaging a normal (anisotropic) kernel over all possible rotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb4fdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "isotropic_kernel = (\n",
    "    kernel + \n",
    "    torch.rot90(kernel, dims=(-2, -1)) + \n",
    "    torch.rot90(kernel, k=-1, dims=(-2, -1)) +\n",
    "    torch.rot90(torch.rot90(kernel, dims=(-2, -1)), dims=(-2, -1))\n",
    ") / 4\n",
    "\n",
    "x = torch.tensor([0., 0.])\n",
    "theta = torch.tensor([torch.pi/2])\n",
    "R = torch.tensor([\n",
    "    [torch.cos(theta), -torch.sin(theta)],\n",
    "    [torch.sin(theta), torch.cos(theta)]\n",
    "])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].set_axis_off()\n",
    "ax[1].set_axis_off()\n",
    "ax[0].set_title(\"Rotate before Convolution\")\n",
    "ax[1].set_title(\"Convolution before Rotate\")\n",
    "ax[0].imshow(conv2d(transform(shoe, x, R), isotropic_kernel, torch.tensor([0.])).squeeze())\n",
    "ax[1].imshow(transform(conv2d(shoe, isotropic_kernel, torch.tensor([0.])), x, R).squeeze());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd89f72",
   "metadata": {},
   "source": [
    "One limitation of this approach is that we are greatly limiting the number of models that can be expressed with the same number of parameters. For example, if we rotate the initial kernel, then that will lead to the same isotropic kernel, even though the kernel parameters are different. This issue can be addressed by _lifting_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fc8457",
   "metadata": {},
   "source": [
    "### Lifting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8529885",
   "metadata": {},
   "source": [
    "Up to now, we have seen images as functions that map the plane $\\mathbb{R}^2$ to a scalar in $\\mathbb{R}$. Roughly speaking, the gray value (or maybe the change thereof) at a given point is a measure of the presence of structure at that location. However, when we look at an image, we can say more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49c2097",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross = torch.zeros(9, 9, 3)\n",
    "cross[4, 1:8] = 1.\n",
    "cross[1:8, 4] = 1.\n",
    "cross[4, 2] = torch.tensor([1., 0., 0.])\n",
    "cross[2, 4] = torch.tensor([0., 0., 1.])\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "ax.set_axis_off()\n",
    "ax.imshow(cross);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afa9024",
   "metadata": {},
   "source": [
    "In this simple image of a cross, we can see that the red point is horizontally oriented, while the blue dot is vertically oriented. In other words, at the position of the red dot and the horizontal orientation, there is structure present, but not at e.g. the position of the red dot and the vertical orientation. Hence, we can ascribe to every position and orientation a gray value; we call this an _orientation score_\n",
    "> **Definition (Orientation Score Transform)** Let $\\psi : \\mathbb{R}^2 \\to \\mathbb{R}$ be a wavelet. Then the _orientation score transform_ $\\mathcal{W}_\\psi$ maps an image $f : \\mathbb{R}^2 \\to \\mathbb{R}$ to an _orientation score_ $\\mathcal{W}_\\psi f : \\mathbb{R}^2 \\times S^1 \\cong \\operatorname{SE}(2) \\to \\mathbb{R}$ via \n",
    "> $$ \\mathcal{W}_\\psi f(\\mathbf{x}, \\theta) = \\int_{\\mathbb{R}^2} ((\\mathbf{x}, R_\\theta) \\psi)(\\mathbf{y}) f(\\mathbf{y}) \\mathrm{d} \\mathbf{y} = \\int_{\\mathbb{R}^2} \\psi(R_\\theta^{-1} (\\mathbf{y} - \\mathbf{x})) f(\\mathbf{y}) \\mathrm{d} \\mathbf{y}. $$\n",
    "Classically, we choose the filter wavelet $\\psi$ to pick up horizontally oriented features; then the gray scale values in the \"image\" $\\mathcal{W}_\\psi f(\\cdot, \\theta): \\mathbb{R}^2 \\to \\mathbb{R}$ are a measure for the presence of a feature at some position with orientation $\\theta$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ecb95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Or = 16\n",
    "cross = torch.zeros(1, 1, 64, 64)\n",
    "cross[..., 31:34, 8:56] = 1.\n",
    "cross[..., 8:56, 31:34] = 1.\n",
    "cakewavelet_lift = LiftM2Cakewavelets(cross.shape[-3], Or, inflection_point=1.)\n",
    "lifted_cross = cakewavelet_lift(cross)\n",
    "\n",
    "k = 0\n",
    "dtheta = 2 * torch.pi / Or\n",
    "fig, ax = plt.subplots(1, 4, figsize=(20, 5))\n",
    "ax[0].set_axis_off()\n",
    "ax[1].set_axis_off()\n",
    "ax[2].set_axis_off()\n",
    "ax[3].set_axis_off()\n",
    "ax[0].set_title(\"$f$\")\n",
    "ax[1].set_title(fr\"$\\mathcal{{W}}_\\psi f(\\cdot , {k * dtheta / torch.pi:.2f} \\pi)$\")\n",
    "ax[2].set_title(fr\"$\\mathcal{{W}}_\\psi f(\\cdot , {(k+Or//4) * dtheta / torch.pi:.2f} \\pi)$\")\n",
    "ax[3].set_title(r\"$\\sum_{\\theta \\in S^1} \\mathcal{W}_\\psi f(\\cdot , \\theta)$\")\n",
    "ax[0].imshow(cross.squeeze())\n",
    "ax[1].imshow(lifted_cross[0, 0, k])\n",
    "ax[2].imshow(lifted_cross[0, 0, k+(Or//4)])\n",
    "ax[3].imshow(lifted_cross.sum(-3).squeeze());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a55aebb",
   "metadata": {},
   "source": [
    "The orientation score transform is equivariant for any wavelet $\\psi$:\n",
    "> **Lemma (Orientation Score Transform is Equivariant)**\n",
    "> Let $\\psi, f: \\mathbb{R}^2 \\to \\mathbb{R}$, and let $g \\in \\operatorname{SE}(2)$. Then,\n",
    "> $$ g (\\mathcal{W}_\\psi f) = \\mathcal{W}_\\psi (g f). $$\n",
    "_proof:_ We can simply rewrite:\n",
    "$$\\begin{split}\n",
    "(\\mathbf{x}, R) (\\mathcal{W}_\\psi f)(\\mathbf{y}, S) & := \\mathcal{W}_\\psi f ((\\mathbf{x}, R)^{-1} (\\mathbf{y}, S)) = \\int_{\\mathbb{R}^2} (\\mathbf{x}, R)^{-1} (\\mathbf{y}, S) \\psi(\\mathbf{z}) f(\\mathbf{z}) \\mathrm{d} \\mathbf{z} = \\int_{\\mathbb{R}^2} \\psi((\\mathbf{y}, S)^{-1} (\\mathbf{x}, R) \\mathbf{z}) f(\\mathbf{z}) \\mathrm{d} \\mathbf{z} \\\\\n",
    "& = \\int_{\\mathbb{R}^2} \\psi((\\mathbf{y}, S)^{-1} \\mathbf{v}) f((\\mathbf{x}, R)^{-1} \\mathbf{v}) \\mathrm{d} (\\mathbf{x}, R)^{-1} \\mathbf{v} \\overset{(1)}{=} \\int_{\\mathbb{R}^2} \\psi((\\mathbf{y}, S)^{-1} \\mathbf{v}) f((\\mathbf{x}, R)^{-1} \\mathbf{v}) \\mathrm{d} \\mathbf{v} \\\\\n",
    "& = \\mathcal{W}_\\psi ((\\mathbf{x}, R) f) (\\mathbf{y}, S),\n",
    "\\end{split}$$\n",
    "where we used the left-invariance of the standard Lebesgue measure in $(1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1264cdb9",
   "metadata": {},
   "source": [
    "We now have a way of lifting images from $\\mathbb{R}^2$ to orientation scores on the group $\\operatorname{SE}(2)$. The next step is to find equivariant operators on such orientation scores. It turns out that convolutions can be generalised to group convolutions. \n",
    "> **Definition (Group Convolution)** Let $G$ be a Lie group, and let $f, k : G \\to \\mathbb{R}$ be functions thereon. Then we define the _group convolution_ of $f$ and $k$ as\n",
    "> $$ (k * f)(g) := \\int_G K(h^{-1} g) f(h) \\mathrm{d} h. $$\n",
    "\n",
    "To get a feel for group convolutions, consider the following examples.\n",
    "> **Example (Convolution on the Translation Group)**\n",
    "> Let $f, k : \\mathbb{R}^2 \\to \\mathbb{R}$. Then, \n",
    "> $$ (k * f)(\\mathbf{x}) := \\int_{\\mathbb{R}^2} k(\\mathbf{x} - \\mathbf{y}) f(\\mathbf{y}) \\mathrm{d} \\mathbf{y}. $$\n",
    "\n",
    "> **Example (Convolution on the Special Orthogonal Group)**\n",
    "> Let $f, k : \\operatorname{SO}(2) \\cong S^1 \\to \\mathbb{R}$. Then, \n",
    "> $$ (k * f)(\\theta) := \\int_{\\operatorname{SO}(2)} k(S^{-1} R_\\theta) f(S) \\mathrm{d} S = \\int_{S^1} k(\\theta - \\phi) f(\\phi) \\mathrm{d} \\phi. $$\n",
    "\n",
    "> **Example (Convolution on the Special Euclidean Group)**\n",
    "> Let $f, k : \\operatorname{SE}(2) \\cong \\mathbb{R}^2 \\times S^1 \\to \\mathbb{R}$. Then, \n",
    "> $$ (k * f)(\\mathbf{x}, \\theta) := \\int_{\\operatorname{SE}(2)} k((\\mathbf{y}, S)^{-1} (\\mathbf{x}, R_\\theta)) f(\\mathbf{y}, S) \\mathrm{d} \\mathbf{y} \\mathrm{d} S = \\int_{\\mathbb{R}^2 \\times S^1} k(R_{\\phi}^{-1} (\\mathbf{x} - \\mathbf{y}), \\theta - \\phi) f(\\mathbf{y}, \\phi) \\mathrm{d} \\mathbf{y} \\mathrm{d} \\phi. $$\n",
    "\n",
    "In the same way that normal convolutions - which are defined on functions on Euclidean space/translation group - are translation equivariant, group convolutions are equivariant to the corresponding group.\n",
    "> **Lemma (Group Convolutions are Equivariant)**\n",
    "> Let $G$ be a Lie group, let $f, k : G \\to \\mathbb{R}$ be functions thereon, and let $r \\in G$. Then, \n",
    "> $$ r (k * f) = k * (r f). $$\n",
    "_proof:_ We can simply rewrite:\n",
    "$$\\begin{split}\n",
    "r (k * f)(g) & := (k * f)(r^{-1} g) := \\int_G K(h^{-1} r^{-1} g) f(h) \\mathrm{d} h = \\int_G k((r h)^{-1} g) f(h) \\mathrm{d} h \\\\\n",
    "& = \\int_G k(q^{-1} g) f(r^{-1} q) \\mathrm{d} r^{-1}q \\overset{(1)}{=} \\int_G k(q^{-1} g) f(r^{-1} q) \\mathrm{d} q \\\\\n",
    "& =  (k * (r f))(g),\n",
    "\\end{split}$$\n",
    "where we used the left-invariance of the Haar measure in $(1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a6830d",
   "metadata": {},
   "source": [
    "In practice, we usually want our output to be an image again, so we need a way to equivariantly map orientation scores to images. We call this projection. We typically use max projection:\n",
    "> **Definition (Max Projection)** Let $f : \\operatorname{SE}(2) \\to \\mathbb{R}$. Then we define the _max projection_ of $f$\n",
    "> $$ \\operatorname{Proj} f(\\mathbf{x}, R) := \\max_{R \\in \\operatorname{SO}(2)} f(\\mathbf{x}, R). $$\n",
    "It is not hard to see that max projection is indeed equivariant:\n",
    "$$\\begin{split}\n",
    "(\\mathbf{x}, R) (\\operatorname{Proj} f)(\\mathbf{y}) & := \\operatorname{Proj} f((\\mathbf{x}, R)^{-1} \\mathbf{y}) = \\operatorname{Proj} f(R^{-1}(\\mathbf{y} - \\mathbf{x})) \\\\\n",
    "& = \\max_{S \\in \\operatorname{SO}(2)} f(R^{-1}(\\mathbf{y} - \\mathbf{x}), S) = \\max_{S \\in \\operatorname{SO}(2)} f(R^{-1}(\\mathbf{y} - \\mathbf{x}), R^{-1} S) = \\max_{S \\in \\operatorname{SO}(2)} (\\mathbf{x}, R) f(\\mathbf{y}, S) \\\\\n",
    "& = (\\operatorname{Proj} (\\mathbf{x}, R) f)(\\mathbf{y}).\n",
    "\\end{split}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b4b015",
   "metadata": {},
   "source": [
    "Hence, one way to make a roto-translation equivariant neural network architecture is as follows:\n",
    "1. Start with a lifting layer that maps images on $\\mathbb{R}^2$ to orientation scores on the group $\\operatorname{SE}(2)$.\n",
    "2. Subsequently apply $\\operatorname{SE}(2)$ group convolutions and point-wise nonlinearities in alternating fashion.\n",
    "3. Project the orientation scores back to images using max projection.\n",
    "\n",
    "Neural networks with this architecture, which mirrors the classical multi-orientation image processing pipeline [2], are called Group equivariant Convolutional Neural Networks (G-CNNs).\n",
    "![Multi-orientation processing pipeline: first lift with the orientation score transform, then perform equivariant processing on the orientation scores, and finally project back down to an image.](multi-orientation_processing.png)\n",
    "\n",
    "For our classification task, the output should not be an image but a \"vector\" in $\\mathbb{P}_c := \\{(p_1, \\ldots, p_c) \\mid \\sum_{i = 1}^c p_i = 1, p_i \\geq 0\\}$, on which the group $\\operatorname{SE}(2)$ acts trivially. We can achieve this by adding additional layers to our network. The output images need to be invariantly converted to numbers, e.g. by taking the maximum over the image, which can then be combined in whatever manner we like. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd070698",
   "metadata": {},
   "source": [
    "Similar approaches can be taken for other affine groups, such as the translation-scaling group and the similarity group. One limitation of lifting is that it increases memory use: if we use $K$ discrete orientations, then the orientation score will use $K$ times as much memory as the image. This problem gets worse for higher dimensional groups, such as the similarity group $\\operatorname{SIM}(2) := \\mathbb{R}^2 \\rtimes (\\operatorname{SO}(2) \\times \\mathbb{R}_+)$, the group of translations, rotations and scalings: if we use $K$ discrete orientations and $M$ discrete scales, memory use will be $K \\times M$ times as large. In other words, memory use scales exponentially in the dimension of the group. Consequently, it is important to choose only the most important symmetries to integrate into the architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711bdbce",
   "metadata": {},
   "source": [
    "## Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d69c5a2",
   "metadata": {},
   "source": [
    "This repository contains two trained models: a CNN and a roto-translation invariant PDE-G-CNN. The architectures can be found in the [`models.py`](models.py) module. The models have trained using the [`train.py`](train.py) script.\n",
    "\n",
    "The CNN is based on the classic LeNet-5 architecture. It consists of two convolutional layers with max-pooling and ReLU activation function, which are (approximately) translation equivariant, followed by three fully connected layers. Notably, the first fully connected layer is _not_ translation invariant, and we also do not have guaranteed translation invariance on the whole model.\n",
    "\n",
    "For our invariant network, we use a PDE-based Group equivariant CNN (PDE-G-CNN) architecture, which were developed in our group by Smets et al. [3]. They are closely related to the Group equivariant CNNs (G-CNNs) described in the previous section. They have a couple of special features:\n",
    "\n",
    "1. Recall that in a G-CNN we alternate the linear convolution layers with point-wise nonlinearities. This is done because alternating linear and nonlinear layers turns out to be necessary to get expressive models. In PDE-G-CNNs, the nonlinear layers no longer act point-wise, but instead are nonlinear convolutions.\n",
    "2. The convolutional layers (approximately) solve PDEs from classical image processing: the convolution kernels are defined in terms of the parameters of these PDEs.\n",
    "\n",
    "It has been shown in various works that PDE-G-CNNs can achieve performance competitive with e.g. CNNs, but with a large reduction in the number of model parameters. Additionally, they tend to be more data efficient, so they can be applied in situations where data is not abundant.\n",
    "\n",
    "![Comparison of a traditional CNN layer and a PDE-G-CNN layer.](layer_comparison.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea59f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([0., 0.])\n",
    "theta = torch.tensor([torch.pi/2])\n",
    "R = torch.tensor([\n",
    "    [torch.cos(theta), -torch.sin(theta)],\n",
    "    [torch.sin(theta), torch.cos(theta)]\n",
    "])\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
    "plot_classification(shoe, pdegcnn, \"PDE-G-CNN\", ax[0, 0])\n",
    "plot_classification(transform(shoe, x, R), pdegcnn, \"PDE-G-CNN\", ax[0, 1])\n",
    "plot_classification(shoe, cnn, \"CNN\", ax[1, 0])\n",
    "plot_classification(transform(shoe, x, R), cnn, \"CNN\", ax[1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cdfc62",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "<a id=\"Smets2024GeometricProcessing\"></a>[1] B.M.N. Smets. Geometric Partial Differential Equations in Deep Learning and Image Processing (2024). <https://research.tue.nl/en/publications/geometric-partial-differential-equations-in-deep-learning-and-ima>\n",
    "\n",
    "```bib\n",
    "@phdthesis{smets2024geometric,\n",
    "  title={Geometric Partial Differential Equations in Deep Learning and Image Processing},\n",
    "  author={Smets, Bart M.N.},\n",
    "  year={2024},\n",
    "  isbn={978-90-386-6133-9},\n",
    "}\n",
    "```\n",
    "\n",
    "<a id=\"Sherry2025DiffusionSpace\"></a>[2] F.M. Sherry, K. Schaefer, R. Duits. Diffusion-Shock PDEs for Deep Learning on Position-Orientation Space. arXiv preprint (2025). <https://doi.org/10.48550/arXiv.2509.06405>\n",
    "\n",
    "```bib\n",
    "@article{sherry2025diffusion,\n",
    "  title={Diffusion-Shock PDEs for Deep Learning on Position-Orientation Space},\n",
    "  author={Sherry, F.M. and Schaefer, K. and Duits, R.},\n",
    "  journal={arXiv preprint},\n",
    "  year={2025},\n",
    "  doi={10.48550/arXiv.2509.06405},\n",
    "}\n",
    "```\n",
    "\n",
    "<a id=\"Smets2022PDENetworks\"></a>[3] B.M.N. Smets, J. Portegies, E.J. Bekkers, R. Duits. PDE-Based Group Equivariant Convolutional Neural Networks. J Math Imaging Vis (2022). <https://doi.org/10.1007/s10851-022-01114-x>\n",
    "\n",
    "```bib\n",
    "@article{smets2022pde,\n",
    "  title={PDE-based Group Equivariant Convolutional Neural Networks},\n",
    "  author={Smets, Bart M.N. and Portegies, Jim and Bekkers, Erik J. and Duits, Remco},\n",
    "  journal={Journal of Mathematical Imaging and Vision},\n",
    "  publisher={Springer},\n",
    "  year={2022},\n",
    "  doi={10.1007/s10851-022-01114-x},\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-lietorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
